<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>利用BP网络实现非线性函数映射（基于matlab工具箱） | Zehua的个人博客</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="大三智能控制课程大作业，基于matlab的神经网络简单实现与训练">
<meta property="og:type" content="article">
<meta property="og:title" content="利用BP网络实现非线性函数映射（基于matlab工具箱）">
<meta property="og:url" content="https://renzehua1998.github.io/2020/05/28/%E5%88%A9%E7%94%A8BP%E7%BD%91%E7%BB%9C%E5%AE%9E%E7%8E%B0%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0%E6%98%A0%E5%B0%84%EF%BC%88%E5%9F%BA%E4%BA%8Ematlab%E5%B7%A5%E5%85%B7%E7%AE%B1%EF%BC%89/index.html">
<meta property="og:site_name" content="Zehua的个人博客">
<meta property="og:description" content="大三智能控制课程大作业，基于matlab的神经网络简单实现与训练">
<meta property="og:locale">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201025162310427.png#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201025162321314.png#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2020102516303332.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY2FyZG8xOTk4,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2020102516304276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY2FyZG8xOTk4,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027171950127.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027172006947.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027172449308.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027172459865.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173107415.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173107328.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173145314.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173145225.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173221576.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173221470.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173302575.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173302432.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173531832.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY2FyZG8xOTk4,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173720713.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173720724.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173720720.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173720712.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173720740.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201027173720739.png">
<meta property="article:published_time" content="2020-05-28T12:42:25.000Z">
<meta property="article:modified_time" content="2022-09-02T06:21:51.410Z">
<meta property="article:author" content="Zehua Ren">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="matlab">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20201025162310427.png#pic_center">
  
    <link rel="alternative" href="/atom.xml" title="Zehua的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  

  
  <!-- 
<script src="/js/av-min.js"></script>
 -->
  <!-- <script src="//unpkg.com/leancloud-storage@3.15.0/dist/av-min.js"></script> -->
  <!-- 
<script src="/js/Valine.min.js"></script>
 -->
  <!-- <script src="//unpkg.com/valine/dist/Valine.min.js"></script> -->
  
  <!-- 
<script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
 -->
  <!-- 
<script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>
 -->
  <!-- 
<script src="/js/require.min.js"></script>
 -->
  
<script src="/js/jquery.min.js"></script>


  
      <!-- <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script> -->
<!-- 此CDN链接已失效，我找了很久的资源，从一个废弃GitHub仓库中找到了对应的js资源可以实现功能 -->
<!-- 由于av-core-mini-0.6.1.js和av-min.js冲突，所以把本位置和源文件的所有AV改成AV0以避免冲突 -->

<script src="/js/av-core-mini-0.6.1.js"></script>

<script>AV0.initialize("w1SO7gpilVpRbakyqOw3qll3-gzGzoHsz", "puuKUoPCcKHPTwmLvShbcaOi");</script>

<script src="/js/Counter.js"></script>

  
<meta name="generator" content="Hexo 6.1.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="mymenucontainer" title="侧栏按钮" onclick="myFunction(this)">
      <div class="bar1"></div>
      <div class="bar2"></div>
      <div class="bar3"></div>
    </div>    
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img src="/img/avatar.jpeg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						
							<div class="icon-wrap icon-ribbon hide" data-idx="1">
								<div class="searchicon"></div>
							</div>
						
						<div class="icon-wrap icon-ribbon hide" data-idx="2">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="3">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="4">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						
						<li>搜索</li>
						
						<li>标签</li>
						
						<li>友链</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		
		<!-- 原开关位置 -->
		
		<div>
			<input id="animation" type="checkbox" onclick="checkboxOnclick(this)"/>
			<a>特效开关</a>
		</div>
		
		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<!-- 单页面内标签位置 -->
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">时间线</a></li>
				        
							<li><a href="/categories">分类</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/Renzehua1998" title="github">github</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/ren-ze-hua-31" title="zhihu">zhihu</a>
					        
								<a class="CSDN" target="_blank" href="https://blog.csdn.net/Ricardo1998" title="CSDN">CSDN</a>
					        
								<a class="cnblogs" target="_blank" href="https://www.cnblogs.com/renzehua" title="cnblogs">cnblogs</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div id="js-search">
						
  <div class="form-group">
    <div class="search-delete" title="清除搜索框" onclick="deleteSearch()">
      <div class="search-bar1"></div>
      <div class="search-bar2"></div>
    </div>
    <input type="text" oninput="gotoSearch()" id="local-search-input" placeholder="在这里输入内容"/>
  </div>  
  <div id="local-search-result">
  </div>
  <div class="search-tags">
    <a href="/tags/CPP/" style="font-size: 10px;">CPP</a> <a href="/tags/CTF/" style="font-size: 10px;">CTF</a> <a href="/tags/C%E8%AF%AD%E8%A8%80/" style="font-size: 18.18px;">C语言</a> <a href="/tags/Julia/" style="font-size: 10.91px;">Julia</a> <a href="/tags/LabVIEW/" style="font-size: 13.64px;">LabVIEW</a> <a href="/tags/Python/" style="font-size: 17.27px;">Python</a> <a href="/tags/git/" style="font-size: 14.55px;">git</a> <a href="/tags/matlab/" style="font-size: 16.36px;">matlab</a> <a href="/tags/%E4%BC%98%E5%8C%96/" style="font-size: 12.73px;">优化</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 10px;">前端</a> <a href="/tags/%E5%9B%BE%E4%B8%8E%E7%BD%91%E7%BB%9C/" style="font-size: 14.55px;">图与网络</a> <a href="/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 11.82px;">图数据库</a> <a href="/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" style="font-size: 20px;">实验报告</a> <a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 10px;">密码学</a> <a href="/tags/%E6%80%81%E5%8A%BF%E6%84%9F%E7%9F%A5/" style="font-size: 11.82px;">态势感知</a> <a href="/tags/%E6%8E%A7%E5%88%B6/" style="font-size: 14.55px;">控制</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" style="font-size: 13.64px;">数据挖掘</a> <a href="/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/" style="font-size: 19.09px;">杂七杂八</a> <a href="/tags/%E6%AD%A3%E5%88%99/" style="font-size: 10px;">正则</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 11.82px;">神经网络</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 14.55px;">算法</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 15.45px;">计网</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 13.64px;">论文阅读</a> <a href="/tags/%E9%80%89%E4%BF%AE%E8%AF%BE/" style="font-size: 12.73px;">选修课</a>
  </div>
  <script>
    function deleteSearch() {
      jQuery("#local-search-input").val('') // 清除搜索内容
      $(".search-tags").css('display', 'block'); // 显示隐藏设置
      $(".search-delete").css('display', 'none');
      let show = document.getElementById('local-search-result'); // 清除原搜索结果
      show.innerHTML=''
    }
    function gotoSearch() { // 执行函数（输入内容改变且不为空时执行搜索，为空时显示tags，隐藏清除按钮）
      let inputStr = jQuery("#local-search-input").val() // 获取输入内容
      if (inputStr !== "") {
        $(".search-tags").css('display', 'none');
        $(".search-delete").css('display', 'block');
        handleSearch(inputStr)
      } else {
        $(".search-tags").css('display', 'block');
        $(".search-delete").css('display', 'none');
        let show = document.getElementById('local-search-result'); // 清除原搜索结果
        show.innerHTML=''
      }
    }
    function handleSearch(inputStr) { // 实施搜索
      let data = JSON.parse(localStorage.getItem('content'))
      inputStr = inputStr.toLowerCase()
      data.forEach((post) => { // 搜索匹配字符串具体位置
        post.matchTitle = false
        post.titleIndex = post.title.toLowerCase().indexOf(inputStr)
        if (post.titleIndex > -1) {
	  			post.matchTitle = true
	  		}

        post.matchText = false
        post.textIndex = post.text.toLowerCase().indexOf(inputStr)
        if (post.textIndex > -1) {
          post.matchText = true
        }

        post.matchTags = false
	  		post.tags.forEach((tag) => {
	  			if (tag.name.toLowerCase().indexOf(inputStr) > -1) {
            post.matchTags = true
	      	}
	  		})
      });

      let htmlStr = '' // 搜索结果html
      htmlStr += '<ul class="search-ul">'
      findPost = false;
      data.forEach((post) => { // 生成展示结果
        if (post.matchTitle || post.matchText || post.matchTags) {
          findPost = true;
          let tagStr = '' // tags标签
          post.tags.forEach((tag) => {
            index = tag.name.toLowerCase().indexOf(inputStr)
            if (index > -1) {
              name = tag.name.slice(0,index)+'<b>'+tag.name.slice(index,index+inputStr.length)+'</b>'+tag.name.slice(index+inputStr.length)
            } else {
              name = tag.name
            }
            tagStr+='<span>#'+name+' </span>'
          })
          if(post.matchTitle) { // 标题
            title = post.title.slice(0,post.titleIndex)
            + '<b>' + post.title.slice(post.titleIndex, post.titleIndex+inputStr.length) + '</b>'
            + post.title.slice(post.titleIndex+inputStr.length)
          } else {
            title = post.title
          }
          if(post.matchText) { // 内容
            text = post.text.slice(post.textIndex-25,post.textIndex)
            + '<b>' + post.text.slice(post.textIndex, post.textIndex+inputStr.length) + '</b>'
            + post.text.slice(post.textIndex+inputStr.length,post.textIndex+inputStr.length+25)
          } else {
            text = post.text.slice(0,50)
          }
          htmlStr+='\
          <li class="search-li">\
            <a href="/'+post.path+'" class="search-title">\
              <span>'+title+'</span>\
            </a>\
            <p class="search-result">\
              '+text+'\
            </p>\
            <p class="search-time">\
              <span>'+post.date.slice(0,10)+'</span>\
            </p>\
            <p class="search-tag">\
              '+tagStr+'\
            </p>\
          </li>';
        }
      })
      if (!findPost) {
        htmlStr+='\
        <li class="search-li">\
          <p class="search-result">\
            没有搜索到相关结果，请清除内容重新搜索或清除浏览器缓存后重试。\
          </p>\
        <\li>'
      }
      htmlStr += '<ul>'
      let show = document.getElementById('local-search-result');
      show.innerHTML=htmlStr
    }
  </script>

					</div>
				</section>
				

				
				<section class="switch-part switch-part3">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/CPP/" style="font-size: 10px;">CPP</a> <a href="/tags/CTF/" style="font-size: 10px;">CTF</a> <a href="/tags/C%E8%AF%AD%E8%A8%80/" style="font-size: 18.18px;">C语言</a> <a href="/tags/Julia/" style="font-size: 10.91px;">Julia</a> <a href="/tags/LabVIEW/" style="font-size: 13.64px;">LabVIEW</a> <a href="/tags/Python/" style="font-size: 17.27px;">Python</a> <a href="/tags/git/" style="font-size: 14.55px;">git</a> <a href="/tags/matlab/" style="font-size: 16.36px;">matlab</a> <a href="/tags/%E4%BC%98%E5%8C%96/" style="font-size: 12.73px;">优化</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 10px;">前端</a> <a href="/tags/%E5%9B%BE%E4%B8%8E%E7%BD%91%E7%BB%9C/" style="font-size: 14.55px;">图与网络</a> <a href="/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 11.82px;">图数据库</a> <a href="/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" style="font-size: 20px;">实验报告</a> <a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 10px;">密码学</a> <a href="/tags/%E6%80%81%E5%8A%BF%E6%84%9F%E7%9F%A5/" style="font-size: 11.82px;">态势感知</a> <a href="/tags/%E6%8E%A7%E5%88%B6/" style="font-size: 14.55px;">控制</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" style="font-size: 13.64px;">数据挖掘</a> <a href="/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/" style="font-size: 19.09px;">杂七杂八</a> <a href="/tags/%E6%AD%A3%E5%88%99/" style="font-size: 10px;">正则</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 11.82px;">神经网络</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 14.55px;">算法</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 15.45px;">计网</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 13.64px;">论文阅读</a> <a href="/tags/%E9%80%89%E4%BF%AE%E8%AF%BE/" style="font-size: 12.73px;">选修课</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part4">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://renzehua1998.github.io/">境外分流</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://renzehua.gitee.io/">国内分流</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://foreverblog.cn/go.html">虫洞</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://echos2019.github.io/Myblog">echos的博客</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://gwyxjtu.github.io">果果的博客</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://patorjk.com/software/taag">字符字母生成</a>
			        
			        </div>
				</section>
				

				
				<section class="switch-part switch-part5">
					<div id="js-aboutme">西北某高校系统工程硕士在读</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
<script>
	// 特效开关
	function checkboxOnclick(checkbox){
		if ( checkbox.checked){
			localStorage.setItem('noanimation','0');
			$(".live2d-widget-container").css('display', 'inline');  // live2d显示
			if (localStorage.getItem('bright') === '1') {
				var circlecolor={"value": ['#999']};
				var linecolor="#999";
				particlesJS0(circlecolor, linecolor);
			}else{
				var circlecolor={"value": ['#0fc', '#0ff', '#ccc', '#ffa500', '#7b5d5f', '#ff945c', '#cfb7c4']};
				var linecolor="#00bfff";
				particlesJS0(circlecolor, linecolor);
			}
		}else{
			localStorage.setItem('noanimation','1');
			$(".live2d-widget-container").css('display', 'none');  // live2d隐藏
			var canvas_el = document.querySelector('#particles-js > .particles-js-canvas-el');
			canvas_el.remove();  // 清除特效
		}
	}
	// 特效函数
	function particlesJS0(circlecolor, linecolor) {
		// require(['/js/particles.js'], function(particlesJS) {
			window.particlesJS('particles-js',

			{
				"particles": {
				"number": {
					"value": 80,
					"density": {
					"enable": true,
					"value_area": 800
					}
				},
				"color": circlecolor,
				"shape": {
					"type": "circle",
					"stroke": {
					"width": 0,
					"color": "#000000"
					},
					"polygon": {
					"nb_sides": 5
					},
					"image": {
					"src": "img/github.svg",
					"width": 100,
					"height": 100
					}
				},
				"opacity": {
					"value": 0.5,
					"random": false,
					"anim": {
					"enable": false,
					"speed": 1,
					"opacity_min": 0.1,
					"sync": false
					}
				},
				"size": {
					"value": 5,
					"random": true,
					"anim": {
					"enable": false,
					"speed": 40,
					"size_min": 0.1,
					"sync": false
					}
				},
				"line_linked": {
					"enable": true,
					"distance": 150,
					"color": linecolor,
					"opacity": 0.4,
					"width": 1
				},
				"move": {
					"enable": true,
					"speed": 6,
					"direction": "none",
					"random": false,
					"straight": false,
					"out_mode": "out",
					"attract": {
					"enable": false,
					"rotateX": 600,
					"rotateY": 1200
					}
				}
				},
				"interactivity": {
				"detect_on": "canvas",
				"events": {
					"onhover": {
					"enable": true,
					"mode": "repulse"
					},
					"onclick": {
					"enable": true,
					"mode": "push"
					},
					"resize": true
				},
				"modes": {
					"grab": {
					"distance": 400,
					"line_linked": {
						"opacity": 1
					}
					},
					"bubble": {
					"distance": 400,
					"size": 40,
					"duration": 2,
					"opacity": 8,
					"speed": 3
					},
					"repulse": {
					"distance": 200
					},
					"push": {
					"particles_nb": 4
					},
					"remove": {
					"particles_nb": 2
					}
				}
				},
				"retina_detect": true,
				"config_demo": {
				"hide_card": false,
				"background_color": "#b61924",
				"background_image": "",
				"background_position": "50% 50%",
				"background_repeat": "no-repeat",
				"background_size": "cover"
				}
			}

			);
		// })
	}
</script>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
		<!-- <div class="search-icon"></div> -->
		
		<p class="animation-info">特效：</p>
		<div id="animation-button" onclick="animOnclick()"></div>
		
  		<h1 class="header-author js-mobile-header hide"></h1>
  	</div>
	<!-- 
  <div class="form-group">
    <div class="search-delete" title="清除搜索框" onclick="deleteSearch()">
      <div class="search-bar1"></div>
      <div class="search-bar2"></div>
    </div>
    <input type="text" oninput="gotoSearch()" id="local-search-input" placeholder="在这里输入内容"/>
  </div>  
  <div id="local-search-result">
  </div>
  <div class="search-tags">
    <a href="/tags/CPP/" style="font-size: 10px;">CPP</a> <a href="/tags/CTF/" style="font-size: 10px;">CTF</a> <a href="/tags/C%E8%AF%AD%E8%A8%80/" style="font-size: 18.18px;">C语言</a> <a href="/tags/Julia/" style="font-size: 10.91px;">Julia</a> <a href="/tags/LabVIEW/" style="font-size: 13.64px;">LabVIEW</a> <a href="/tags/Python/" style="font-size: 17.27px;">Python</a> <a href="/tags/git/" style="font-size: 14.55px;">git</a> <a href="/tags/matlab/" style="font-size: 16.36px;">matlab</a> <a href="/tags/%E4%BC%98%E5%8C%96/" style="font-size: 12.73px;">优化</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 10px;">前端</a> <a href="/tags/%E5%9B%BE%E4%B8%8E%E7%BD%91%E7%BB%9C/" style="font-size: 14.55px;">图与网络</a> <a href="/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 11.82px;">图数据库</a> <a href="/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" style="font-size: 20px;">实验报告</a> <a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 10px;">密码学</a> <a href="/tags/%E6%80%81%E5%8A%BF%E6%84%9F%E7%9F%A5/" style="font-size: 11.82px;">态势感知</a> <a href="/tags/%E6%8E%A7%E5%88%B6/" style="font-size: 14.55px;">控制</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" style="font-size: 13.64px;">数据挖掘</a> <a href="/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/" style="font-size: 19.09px;">杂七杂八</a> <a href="/tags/%E6%AD%A3%E5%88%99/" style="font-size: 10px;">正则</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 11.82px;">神经网络</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 14.55px;">算法</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 15.45px;">计网</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 13.64px;">论文阅读</a> <a href="/tags/%E9%80%89%E4%BF%AE%E8%AF%BE/" style="font-size: 12.73px;">选修课</a>
  </div>
  <script>
    function deleteSearch() {
      jQuery("#local-search-input").val('') // 清除搜索内容
      $(".search-tags").css('display', 'block'); // 显示隐藏设置
      $(".search-delete").css('display', 'none');
      let show = document.getElementById('local-search-result'); // 清除原搜索结果
      show.innerHTML=''
    }
    function gotoSearch() { // 执行函数（输入内容改变且不为空时执行搜索，为空时显示tags，隐藏清除按钮）
      let inputStr = jQuery("#local-search-input").val() // 获取输入内容
      if (inputStr !== "") {
        $(".search-tags").css('display', 'none');
        $(".search-delete").css('display', 'block');
        handleSearch(inputStr)
      } else {
        $(".search-tags").css('display', 'block');
        $(".search-delete").css('display', 'none');
        let show = document.getElementById('local-search-result'); // 清除原搜索结果
        show.innerHTML=''
      }
    }
    function handleSearch(inputStr) { // 实施搜索
      let data = JSON.parse(localStorage.getItem('content'))
      inputStr = inputStr.toLowerCase()
      data.forEach((post) => { // 搜索匹配字符串具体位置
        post.matchTitle = false
        post.titleIndex = post.title.toLowerCase().indexOf(inputStr)
        if (post.titleIndex > -1) {
	  			post.matchTitle = true
	  		}

        post.matchText = false
        post.textIndex = post.text.toLowerCase().indexOf(inputStr)
        if (post.textIndex > -1) {
          post.matchText = true
        }

        post.matchTags = false
	  		post.tags.forEach((tag) => {
	  			if (tag.name.toLowerCase().indexOf(inputStr) > -1) {
            post.matchTags = true
	      	}
	  		})
      });

      let htmlStr = '' // 搜索结果html
      htmlStr += '<ul class="search-ul">'
      findPost = false;
      data.forEach((post) => { // 生成展示结果
        if (post.matchTitle || post.matchText || post.matchTags) {
          findPost = true;
          let tagStr = '' // tags标签
          post.tags.forEach((tag) => {
            index = tag.name.toLowerCase().indexOf(inputStr)
            if (index > -1) {
              name = tag.name.slice(0,index)+'<b>'+tag.name.slice(index,index+inputStr.length)+'</b>'+tag.name.slice(index+inputStr.length)
            } else {
              name = tag.name
            }
            tagStr+='<span>#'+name+' </span>'
          })
          if(post.matchTitle) { // 标题
            title = post.title.slice(0,post.titleIndex)
            + '<b>' + post.title.slice(post.titleIndex, post.titleIndex+inputStr.length) + '</b>'
            + post.title.slice(post.titleIndex+inputStr.length)
          } else {
            title = post.title
          }
          if(post.matchText) { // 内容
            text = post.text.slice(post.textIndex-25,post.textIndex)
            + '<b>' + post.text.slice(post.textIndex, post.textIndex+inputStr.length) + '</b>'
            + post.text.slice(post.textIndex+inputStr.length,post.textIndex+inputStr.length+25)
          } else {
            text = post.text.slice(0,50)
          }
          htmlStr+='\
          <li class="search-li">\
            <a href="/'+post.path+'" class="search-title">\
              <span>'+title+'</span>\
            </a>\
            <p class="search-result">\
              '+text+'\
            </p>\
            <p class="search-time">\
              <span>'+post.date.slice(0,10)+'</span>\
            </p>\
            <p class="search-tag">\
              '+tagStr+'\
            </p>\
          </li>';
        }
      })
      if (!findPost) {
        htmlStr+='\
        <li class="search-li">\
          <p class="search-result">\
            没有搜索到相关结果，请清除内容重新搜索或清除浏览器缓存后重试。\
          </p>\
        <\li>'
      }
      htmlStr += '<ul>'
      let show = document.getElementById('local-search-result');
      show.innerHTML=htmlStr
    }
  </script>
 -->
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/avatar.jpeg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			</div>
			<hgroup>
			  <h1 class="header-author"></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">时间线</a></li>
		        
					<li><a href="/categories">分类</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Renzehua1998" title="github">github</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/ren-ze-hua-31" title="zhihu">zhihu</a>
			        
						<a class="CSDN" target="_blank" href="https://blog.csdn.net/Ricardo1998" title="CSDN">CSDN</a>
			        
						<a class="cnblogs" target="_blank" href="https://www.cnblogs.com/renzehua" title="cnblogs">cnblogs</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

<script>
	// 特效开关
	function animOnclick(){
		if (localStorage.getItem('noanimation') === '1'){
			$("#animation-button").attr('class','animation-off');
			localStorage.setItem('noanimation','0');
			if (localStorage.getItem('bright') === '1') {
				var circlecolor={"value": ['#999']};
				var linecolor="#999";
				particlesJS0(circlecolor, linecolor);
			}else{
				var circlecolor={"value": ['#0fc', '#0ff', '#ccc', '#ffa500', '#7b5d5f', '#ff945c', '#cfb7c4']};
				var linecolor="#00bfff";
				particlesJS0(circlecolor, linecolor);
			}
		}else{
			$("#animation-button").attr('class','animation-on');
			localStorage.setItem('noanimation','1');
			var canvas_el = document.querySelector('#particles-js > .particles-js-canvas-el');
			canvas_el.remove();  // 清除特效
		}
	}
	// 特效函数
	function particlesJS0(circlecolor, linecolor) {
		// require(['/js/particles.js'], function(particlesJS) {
			window.particlesJS('particles-js',

			{
				"particles": {
				"number": {
					"value": 80,
					"density": {
					"enable": true,
					"value_area": 800
					}
				},
				"color": circlecolor,
				"shape": {
					"type": "circle",
					"stroke": {
					"width": 0,
					"color": "#000000"
					},
					"polygon": {
					"nb_sides": 5
					},
					"image": {
					"src": "img/github.svg",
					"width": 100,
					"height": 100
					}
				},
				"opacity": {
					"value": 0.5,
					"random": false,
					"anim": {
					"enable": false,
					"speed": 1,
					"opacity_min": 0.1,
					"sync": false
					}
				},
				"size": {
					"value": 5,
					"random": true,
					"anim": {
					"enable": false,
					"speed": 40,
					"size_min": 0.1,
					"sync": false
					}
				},
				"line_linked": {
					"enable": true,
					"distance": 150,
					"color": linecolor,
					"opacity": 0.4,
					"width": 1
				},
				"move": {
					"enable": true,
					"speed": 6,
					"direction": "none",
					"random": false,
					"straight": false,
					"out_mode": "out",
					"attract": {
					"enable": false,
					"rotateX": 600,
					"rotateY": 1200
					}
				}
				},
				"interactivity": {
				"detect_on": "canvas",
				"events": {
					"onhover": {
					"enable": true,
					"mode": "repulse"
					},
					"onclick": {
					"enable": true,
					"mode": "push"
					},
					"resize": true
				},
				"modes": {
					"grab": {
					"distance": 400,
					"line_linked": {
						"opacity": 1
					}
					},
					"bubble": {
					"distance": 400,
					"size": 40,
					"duration": 2,
					"opacity": 8,
					"speed": 3
					},
					"repulse": {
					"distance": 200
					},
					"push": {
					"particles_nb": 4
					},
					"remove": {
					"particles_nb": 2
					}
				}
				},
				"retina_detect": true,
				"config_demo": {
				"hide_card": false,
				"background_color": "#b61924",
				"background_image": "",
				"background_position": "50% 50%",
				"background_repeat": "no-repeat",
				"background_size": "cover"
				}
			}

			);
		// })
	}
</script>
      <div class="body-wrap"><article id="post-利用BP网络实现非线性函数映射（基于matlab工具箱）" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/05/28/%E5%88%A9%E7%94%A8BP%E7%BD%91%E7%BB%9C%E5%AE%9E%E7%8E%B0%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0%E6%98%A0%E5%B0%84%EF%BC%88%E5%9F%BA%E4%BA%8Ematlab%E5%B7%A5%E5%85%B7%E7%AE%B1%EF%BC%89/" class="article-date">
  	<time datetime="2020-05-28T12:42:25.000Z" itemprop="datePublished">2020-05-28</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      利用BP网络实现非线性函数映射（基于matlab工具箱）
      
    </h1>
  

        
          <div style="margin-top:10px;">
    <span class="post-time">
      <span class="post-meta-item-icon">
        <i class="fa fa-keyboard-o"></i>
        <span class="post-meta-item-text">  全文共: </span>
        <span class="post-count">3.2k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
        <i class="fa fa-hourglass-half"></i>
        <span class="post-meta-item-text">  阅读时长: </span>
        <span class="post-count">13分</span>
      </span>
    </span>
</div>
        
      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/matlab/" rel="tag">matlab</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/">知识整理</a><a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/">本科课程</a><a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E4%B8%89%E4%B8%8B/">大三下</a>
	</div>


        
          
<div class="counter-tag counter">
    <span id="/2020/05/28/%E5%88%A9%E7%94%A8BP%E7%BD%91%E7%BB%9C%E5%AE%9E%E7%8E%B0%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0%E6%98%A0%E5%B0%84%EF%BC%88%E5%9F%BA%E4%BA%8Ematlab%E5%B7%A5%E5%85%B7%E7%AE%B1%EF%BC%89/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="利用BP网络实现非线性函数映射（基于matlab工具箱）">
         &nbsp;
        阅读
    </span>
</div>

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
          <!-- Table of Contents -->

          <!-- version1 -->
          <!-- 
            <div id="toc" class="toc-article">
            <strong class="toc-title">文章目录</strong>
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">1.</span> <span class="toc-text">一、网络结构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text">二、学习过程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E5%AD%A6%E4%B9%A0%E7%BB%93%E6%9E%9C"><span class="toc-number">3.</span> <span class="toc-text">三、学习结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90"><span class="toc-number">4.</span> <span class="toc-text">四、误差分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">五、实验总结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%99%84%E5%BD%95%E6%BA%90%E7%A8%8B%E5%BA%8F"><span class="toc-number">6.</span> <span class="toc-text">附录（源程序）</span></a></li></ol>
            </div>
           -->

          <!-- version2 -->
          
            <p class="show-toc-btn" id="show-toc-btn" onclick="showToc();">
            <strong class="btn-text">文章导航</strong>
            </p>
            <div id="toc-article" class="toc-article" style="display:none">
                <span id="toc-close" class="toc-close" title="隐藏导航" onclick="showBtn();">×</span>
                <strong class="toc-title">文章目录</strong>
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">1.</span> <span class="toc-text">一、网络结构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text">二、学习过程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E5%AD%A6%E4%B9%A0%E7%BB%93%E6%9E%9C"><span class="toc-number">3.</span> <span class="toc-text">三、学习结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90"><span class="toc-number">4.</span> <span class="toc-text">四、误差分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">五、实验总结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%99%84%E5%BD%95%E6%BA%90%E7%A8%8B%E5%BA%8F"><span class="toc-number">6.</span> <span class="toc-text">附录（源程序）</span></a></li></ol>
            </div>
            <script type="text/javascript">
              function showToc(){
                  var toc_article = document.getElementById("toc-article");
                  var show_toc_btn = document.getElementById("show-toc-btn");
                  toc_article.setAttribute("style","display:block");
                  show_toc_btn.setAttribute("style","display:none");
                  };
              function showBtn(){
                  var toc_article = document.getElementById("toc-article");
                  var show_toc_btn = document.getElementById("show-toc-btn");
                  toc_article.setAttribute("style","display:none");
                  show_toc_btn.setAttribute("style","display:block");
                  };
            </script>
          
          <p>大三智能控制课程大作业，基于matlab的神经网络简单实现与训练</p>
<span id="more"></span>
<p><strong>实验目的</strong>：自己设计一个BP网络实现非线性函数映射</p>
<p><strong>基本要求</strong>：设有两输入单输出函数 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.781ex" xmlns="http://www.w3.org/2000/svg" width="26.35ex" height="2.667ex" role="img" focusable="false" viewBox="0 -833.9 11646.7 1178.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(939,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1511,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1955.7,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2445.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3112.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(4168.2,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msup" transform="translate(4668.2,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(5899,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(6899.2,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(7368.2,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7713.2,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(8313.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(8702.2,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(9414.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mfrac" transform="translate(10414.7,0)"><g data-mml-node="mi" transform="translate(220,394) scale(0.707)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mn" transform="translate(244.7,-345) scale(0.707)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><rect width="603.1" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(11257.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p>
<p>其中自变量x,y的取值范围为 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="9.368ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4140.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1167,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(1667,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mo" transform="translate(2237,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(2681.7,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(3181.7,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mo" transform="translate(3751.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span> 试设计一个BP网络实现此函数映射。要求以完整的实验报告形式描述网络的结构、学习过程、结果，以附录形式附源程序。</p>
<h1 id="一网络结构">一、网络结构</h1>
<p>首先建立简单的BP神经网络模型，隐层神经元个数为10，输入二维，为函数的两个自变量x和y，输出为函数值的估计值，为一维。</p>
<p align="middle">
<img src="https://img-blog.csdnimg.cn/20201025162310427.png#pic_center" alt="在这里插入图片描述">
<p>
<p>在此基础上建立三层BP神经网络，两个隐层神经元个数都为10，输入二维，为函数的两个自变量x和y，输出为函数值的估计值，为一维。</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20201025162321314.png#pic_center" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<h1 id="二学习过程">二、学习过程</h1>
<p>使用自己编写的子函数GetInput生成训练数据，可以自行指定生成的数据个数。调用格式为：[Input,Output] = GetInput(SampleNum)</p>
<p><strong>（1）首先尝试自己通过编程实现简单的BP网络</strong></p>
<p>参数设置为： 总体样本30个，其中训练样本21个，验证样本5个，测试样本4个。 最多训练次数为10000次，允许误差选为10-7，学习速率为0.01。 传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="5.42ex" height="1.783ex" role="img" focusable="false" viewBox="0 -583 2395.6 788"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（purelin）最简单的一一对应关系。 训练算法为梯度下降法，不断地对权值矩阵W1、W2，阈值矩阵B1、B2进行修正，最终达到训练效果。</p>
<p><strong>（2）利用matlab自带的神经网络工具箱搭建BP网络</strong></p>
<p>备注：也尝试了GUI界面编程，但是无法以代码形式展现，其工作过程与命令行操作相同。 一共构建了两个网络：10-10-1和10-1，即第一部分中提到的两个网络。 网络10-10-1参数设置为： 总体样本分别为100个和1000个，其中训练样本70%，验证样本15%，测试样本15%。 最多训练次数为10000次，允许误差选为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex" xmlns="http://www.w3.org/2000/svg" width="4.495ex" height="2.02ex" role="img" focusable="false" viewBox="0 -871.1 1986.7 893.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,393.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path></g></g></g></g></g></svg></mjx-container></span>，学习速率为0.01，动量因子为0.9。 隐层传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.912ex" xmlns="http://www.w3.org/2000/svg" width="9.571ex" height="3.052ex" role="img" focusable="false" viewBox="0 -946.2 4230.4 1349.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1823.6,0)"><g data-mml-node="mrow" transform="translate(220,398) scale(0.707)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1278,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(1278,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,289) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g><rect width="2166.9" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span>（tansig），输出层传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="5.42ex" height="1.783ex" role="img" focusable="false" viewBox="0 -583 2395.6 788"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（purelin）。 训练算法为神经网络训练中常用的L-M算法（trainlm） 网络10-1参数设置为： 总体样本分别为100个、300个、500个和1000个，其中训练样本70%，验证样本15%，测试样本15%。 最多训练次数为10000次，允许误差选为10-7，学习速率为0.01，动量因子为0.9。 隐层传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.912ex" xmlns="http://www.w3.org/2000/svg" width="9.571ex" height="3.052ex" role="img" focusable="false" viewBox="0 -946.2 4230.4 1349.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1823.6,0)"><g data-mml-node="mrow" transform="translate(220,398) scale(0.707)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1278,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(1278,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,289) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g><rect width="2166.9" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span>（tansig），输出层传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="5.42ex" height="1.783ex" role="img" focusable="false" viewBox="0 -583 2395.6 788"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（purelin）。 训练算法为神经网络训练中常用的L-M算法（trainlm）</p>
<h1 id="三学习结果">三、学习结果</h1>
<p><strong>（1）自己编程搭建的BP神经网络</strong></p>
<figure>
<img src="https://img-blog.csdnimg.cn/2020102516303332.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY2FyZG8xOTk4,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<p align="middle">
30个训练样本和30个随机样本的验证结果
<p>
<figure>
<img src="https://img-blog.csdnimg.cn/2020102516304276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY2FyZG8xOTk4,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<p align="middle">
网络学习结果拟合图
<p>
<p><strong>（2）神经网络工具箱搭建的BP网络</strong></p>
Net1：10-10-1，100个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027171950127.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027172006947.png" width="300" height="400"></p>
</div>
Net2：10-1，100个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027172449308.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027172459865.png" width="300" height="400"></p>
</div>
Net3：10-1，300个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173107415.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027173107328.png" width="300" height="400"></p>
</div>
Net4：10-1，500个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173145314.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027173145225.png" width="300" height="400"></p>
</div>
Net5：10-1，1000个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173221576.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027173221470.png" width="300" height="400"></p>
</div>
Net6：10-10-1，1000个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173302575.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027173302432.png" width="300" height="400"></p>
</div>
<h1 id="四误差分析">四、误差分析</h1>
<p><strong>（1）自己编程搭建的BP神经网络</strong></p>
<p>标准差：3.5937</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20201027173531832.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY2FyZG8xOTk4,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<p><strong>（2）神经网络工具箱搭建的BP网络</strong></p>
标准差：<br>
40.4614 / 0.8592 / 0.0310 0.5113 / 0.2013 / 0.2013
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173720713.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720724.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720720.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720712.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720740.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720739.png" width="300" height="300"></p>
</div>
<h1 id="五实验总结">五、实验总结</h1>
<p>这次实验中，我先尝试使用matlab自己编写了BP神经网络，输入映射函数使用最简单的y=x，训练算法采用梯度下降法。在实际操作中我发现当训练样本数大于28时，极有可能会陷入局部最优解，导致神经网络误差偏大，当训练样本数大于57时，误差甚至会随着迭代次数的增加而发散，这也是最基础的神经网络中难以避免的问题。20多个训练样本是比较合适的，所以总样本数选取了30。在训练样本和随机样本的检测下都显示出了比较好的效果。最后误差检验的结果显示，拟合图比较均匀地分布在直线两侧，标准差也不算太大。 由于经典梯度下降法有着各种各样的问题，我在调用神经网络工具箱时采用了现在普遍使用的L-M算法，同时也尝试搭建了三层的BP神经网络。在两层神经网络中，预测精度得到了明显的提高，而且随着训练样本的增加，精度也有提高的趋势。然而事情也并非绝对，在精度达到一个阈值时，即使增加样本，精度也不会有明显的提高。而且训练有着一定的偶然性，即使样本数很少，初始条件选择合适的话也会比样本数多的模型精度更高。而三层网络在训练样本数少时预测效果反而没有两层的好，当样本数较多时效果和两层模型相同，这也提醒我，当问题比较简单时，不要贸然增加网络深度，有时候网络过深也不见得是一件好事。</p>
<h1 id="附录源程序">附录（源程序）</h1>
<p><strong>（1）自编 训练函数：</strong> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% function main()</span></span><br><span class="line">clc                          <span class="comment">% 清屏</span></span><br><span class="line">clear all;                  <span class="comment">%清除内存以便加快运算速度</span></span><br><span class="line">close all;                  <span class="comment">%关闭当前所有figure图像</span></span><br><span class="line">Num=<span class="number">30</span>;                   <span class="comment">%所有样本总个数</span></span><br><span class="line">TrainSamNum=<span class="number">0.7</span>*Num;              <span class="comment">%输入样本数量为21</span></span><br><span class="line">ValSamNum=<span class="number">1</span>/<span class="number">6</span>*Num;               <span class="comment">%验证样本数量为5</span></span><br><span class="line">TestSamNum=<span class="number">2</span>/<span class="number">15</span>*Num;              <span class="comment">%测试样本数量也是4</span></span><br><span class="line">HiddenUnitNum=<span class="number">10</span>;            <span class="comment">%中间层隐节点数量取10</span></span><br><span class="line">InDim=<span class="number">2</span>;                    <span class="comment">%网络输入维度为2</span></span><br><span class="line">OutDim=<span class="number">1</span>;                   <span class="comment">%网络输出维度为1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%原始数据 </span></span><br><span class="line">[p,t] = GetInput(Num);<span class="comment">%生成输出p和输入t</span></span><br><span class="line"><span class="comment">%输入数据矩阵p</span></span><br><span class="line"><span class="comment">%目标数据矩阵t</span></span><br><span class="line">[SamIn,minp,maxp,SamOut,mint,maxt]=premnmx(p,t); <span class="comment">%原始样本对（输入和输出）初始化,进行了数据的归一化</span></span><br><span class="line">[TrainSamIn,ValSamIn,TestSamIn] =divideblock(SamIn,<span class="number">0.7</span>,<span class="number">1</span>/<span class="number">6</span>,<span class="number">2</span>/<span class="number">15</span>);</span><br><span class="line">[TrainSamOut,ValSamOut,TestSamOut] =divideblock(SamOut,<span class="number">0.7</span>,<span class="number">1</span>/<span class="number">6</span>,<span class="number">2</span>/<span class="number">15</span>);</span><br><span class="line"><span class="built_in">rand</span>(<span class="string">'state'</span>,sum(<span class="number">100</span>*clock))   <span class="comment">%依据系统时钟种子产生随机数         </span></span><br><span class="line">NoiseVar=<span class="number">0.01</span>;                    <span class="comment">%噪声强度为0.01（添加噪声的目的是为了防止网络过度拟合）</span></span><br><span class="line">Noise=NoiseVar*<span class="built_in">randn</span>(<span class="number">1</span>,TrainSamNum);   <span class="comment">%生成噪声</span></span><br><span class="line">TrainSamOut=TrainSamOut + Noise;                   <span class="comment">%将噪声添加到输出样本上</span></span><br><span class="line"></span><br><span class="line">MaxEpochs=<span class="number">10000</span>;                              <span class="comment">%最多训练次数为10000</span></span><br><span class="line">lr=<span class="number">0.01</span>;                                      <span class="comment">%学习速率为0.01</span></span><br><span class="line">E0=<span class="number">1e-7</span>;                                      <span class="comment">%目标误差为1e-7</span></span><br><span class="line">W1=<span class="number">0.5</span>*<span class="built_in">rand</span>(HiddenUnitNum,InDim)<span class="number">-0.1</span>;   <span class="comment">%初始化输入层与隐含层之间的权值</span></span><br><span class="line">B1=<span class="number">0.5</span>*<span class="built_in">rand</span>(HiddenUnitNum,<span class="number">1</span>)<span class="number">-0.1</span>;       <span class="comment">%初始化输入层与隐含层之间的阈值</span></span><br><span class="line">W2=<span class="number">0.5</span>*<span class="built_in">rand</span>(OutDim,HiddenUnitNum)<span class="number">-0.1</span>; <span class="comment">%初始化输出层与隐含层之间的权值              </span></span><br><span class="line">B2=<span class="number">0.5</span>*<span class="built_in">rand</span>(OutDim,<span class="number">1</span>)<span class="number">-0.1</span>;                <span class="comment">%初始化输出层与隐含层之间的阈值</span></span><br><span class="line">W11=W1;W22=W2;B11=B1;B22=B2;</span><br><span class="line"></span><br><span class="line">ErrHistory=[];                              <span class="comment">%给中间变量预先占据内存</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:MaxEpochs</span><br><span class="line">    </span><br><span class="line">    HiddenOut=logsig(W1*TrainSamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,TrainSamNum)); <span class="comment">% 隐含层网络输出</span></span><br><span class="line">    NetworkOut=W2*HiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,TrainSamNum);    <span class="comment">% 输出层网络输出</span></span><br><span class="line">    Error=TrainSamOut-NetworkOut;                       <span class="comment">% 实际输出与网络输出之差</span></span><br><span class="line">    SSE=sumsqr(Error);                               <span class="comment">%能量函数（误差平方和）</span></span><br><span class="line"></span><br><span class="line">    ErrHistory=[ErrHistory SSE];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> SSE&lt;E0,<span class="keyword">break</span>, <span class="keyword">end</span>      <span class="comment">%如果达到误差要求则跳出学习循环</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 下面是权值（阈值）依据能量函数负梯度下降原理所作的每一步动态调整量</span></span><br><span class="line">    Delta2=Error;</span><br><span class="line">    Delta1=W2'*Delta2.*HiddenOut.*(<span class="number">1</span>-HiddenOut);    </span><br><span class="line"></span><br><span class="line">    dW2=Delta2*HiddenOut';</span><br><span class="line">    dB2=Delta2*<span class="built_in">ones</span>(TrainSamNum,<span class="number">1</span>);</span><br><span class="line">    </span><br><span class="line">    dW1=Delta1*TrainSamIn';</span><br><span class="line">    dB1=Delta1*<span class="built_in">ones</span>(TrainSamNum,<span class="number">1</span>);</span><br><span class="line">    <span class="comment">%对输出层与隐含层之间的权值和阈值进行修正</span></span><br><span class="line">    W2=W2+lr*dW2;</span><br><span class="line">    B2=B2+lr*dB2;</span><br><span class="line">    <span class="comment">%对输入层与隐含层之间的权值和阈值进行修正</span></span><br><span class="line">    W1=W1+lr*dW1;</span><br><span class="line">    B1=B1+lr*dB1;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">SSE   <span class="comment">%显示最终误差</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%拟合图</span></span><br><span class="line">TrainHiddenOut=logsig(W1*TrainSamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,TrainSamNum)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">TrainNetworkOut=W2*TrainHiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,TrainSamNum);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">Trainoutput=postmnmx(TrainNetworkOut,mint,maxt);               <span class="comment">% 还原网络输出层的结果</span></span><br><span class="line">ValHiddenOut=logsig(W1*ValSamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,ValSamNum)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">ValNetworkOut=W2*ValHiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,ValSamNum);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">Valoutput=postmnmx(ValNetworkOut,mint,maxt);               <span class="comment">% 还原网络输出层的结果</span></span><br><span class="line">TestHiddenOut=logsig(W1*TestSamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,TestSamNum)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">TestNetworkOut=W2*TestHiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,TestSamNum);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">Testoutput=postmnmx(TestNetworkOut,mint,maxt);               <span class="comment">% 还原网络输出层的结果</span></span><br><span class="line">[TrainSamOut,ValSamOut,TestSamOut] =divideblock(t,<span class="number">0.7</span>,<span class="number">1</span>/<span class="number">6</span>,<span class="number">2</span>/<span class="number">15</span>); <span class="comment">%还原原始输出</span></span><br><span class="line">Tolvalue=[TrainSamOut,ValSamOut,TestSamOut];</span><br><span class="line">Toloutput=[Trainoutput Valoutput Testoutput];</span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">plotregression(TrainSamOut,Trainoutput,<span class="string">'训练'</span>,ValSamOut,Valoutput,<span class="string">'验证'</span>,...</span><br><span class="line">    TestSamOut,Testoutput,<span class="string">'测试'</span>,Tolvalue,Toloutput,<span class="string">'全体'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">%绘制网络输出与真实输出的对比图</span></span><br><span class="line">HiddenOut=logsig(W1*SamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,Num)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">NetworkOut=W2*HiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,Num);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">newk=postmnmx(NetworkOut,mint,maxt);               </span><br><span class="line">x=<span class="number">1</span>:Num; </span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);<span class="built_in">plot</span>(x,newk,<span class="string">'r-o'</span>,x,t,<span class="string">'b--+'</span>)    <span class="comment">%绘对比图；</span></span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'网络输出'</span>,<span class="string">'实际输出'</span>);</span><br><span class="line">title(<span class="string">'训练样本的预测结果'</span>)</span><br><span class="line">[p1,t1] = GetInput(Num);<span class="comment">%生成检验的输出p1和输入t1</span></span><br><span class="line">[SamIn1,minp,maxp]=premnmx(p1);<span class="comment">%归一化</span></span><br><span class="line">HiddenOut=logsig(W1*SamIn1+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,Num)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">NetworkOut=W2*HiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,Num);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">newk1=postmnmx(NetworkOut,mint,maxt);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);<span class="built_in">plot</span>(x,newk1,<span class="string">'r-o'</span>,x,t1,<span class="string">'b--+'</span>)    <span class="comment">%绘对比图；</span></span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'网络输出'</span>,<span class="string">'实际输出'</span>);</span><br><span class="line">title(<span class="string">'随机验证的预测结果'</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>误差检验：</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[p,t] = GetInput(<span class="number">1000</span>);<span class="comment">%生成输出p和输入t</span></span><br><span class="line">[SamIn,minp,maxp,tn,mint,maxt]=premnmx(p,t); <span class="comment">%原始样本对（输入和输出）初始化,进行了数据的归一化</span></span><br><span class="line">HiddenOut=logsig(W1*SamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,<span class="number">1000</span>)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">NetworkOut=W2*HiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,<span class="number">1000</span>);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">newk=postmnmx(NetworkOut,mint,maxt);               </span><br><span class="line"><span class="built_in">figure</span>;plotregression(t,newk,<span class="string">'自编函数'</span>)</span><br><span class="line">E = t-newk;</span><br><span class="line">std(E)</span><br><span class="line"><span class="comment">% 一次运行结果：3.5937</span></span><br></pre></td></tr></table></figure>
<p><strong>（2）神经网络工具箱 训练函数：</strong> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">clear all</span><br><span class="line">[p,t] = GetInput(<span class="number">30</span>);<span class="comment">%生成输出p和输入t</span></span><br><span class="line">[p1,ps]=mapminmax(p);<span class="comment">%归一化</span></span><br><span class="line">[t1,ts]=mapminmax(t);</span><br><span class="line"><span class="comment">%分割为训练数据、验证数据、测试数据</span></span><br><span class="line">[trainsample.p,valsample.p,testsample.p] =divideblock(p,<span class="number">0.7</span>,<span class="number">0.15</span>,<span class="number">0.15</span>);</span><br><span class="line">[trainsample.t,valsample.t,testsample.t] =divideblock(t,<span class="number">0.7</span>,<span class="number">0.15</span>,<span class="number">0.15</span>);</span><br><span class="line"><span class="comment">%关于net函数的参数说明：net = newff(minmax(p),[隐层的神经元的个数，输出层的神经元的个数],...</span></span><br><span class="line"><span class="comment">% {隐层神经元的传输函数，输出层的传输函数｝,'反向传播的训练函数'),其中p为输入数据，t为输出数据</span></span><br><span class="line">TF1=<span class="string">'tansig'</span>;TF2=<span class="string">'purelin'</span>;</span><br><span class="line">net=newff(minmax(p),[<span class="number">10</span>,<span class="number">1</span>],{TF1 TF2},<span class="string">'trainlm'</span>);<span class="comment">%创建BP神经网络，隐层10个神经元，两层（不包括输入层）</span></span><br><span class="line"><span class="comment">%训练算法为Levenberg-Marquardt算法</span></span><br><span class="line"><span class="comment">%网络参数的设置</span></span><br><span class="line">net.trainParam.epochs=<span class="number">10000</span>;<span class="comment">%训练次数</span></span><br><span class="line">net.trainParam.goal=<span class="number">1e-7</span>;<span class="comment">%训练精度</span></span><br><span class="line">net.trainParam.lr=<span class="number">0.01</span>;<span class="comment">%学习率</span></span><br><span class="line">net.trainParam.mc=<span class="number">0.9</span>;<span class="comment">%动量因子</span></span><br><span class="line">net.trainParam.show=<span class="number">25</span>;<span class="comment">%显示间隔次数</span></span><br><span class="line">[net,tr]=train(net,trainsample.p,trainsample.t);<span class="comment">%训练网络</span></span><br><span class="line"><span class="comment">%计算仿真</span></span><br><span class="line">[normtrainoutput,trainPerf]=sim(net,trainsample.p,[],[],trainsample.t);<span class="comment">%训练的数据经BP得到的结果</span></span><br><span class="line">[normvalidateoutput,validatePerf]=sim(net,valsample.p,[],[],valsample.t);<span class="comment">%验证的数据经BP得到的结果</span></span><br><span class="line">[normtestoutput,testPerf]=sim(net,testsample.p,[],[],testsample.t);<span class="comment">%测试数据经BP得到的结果</span></span><br><span class="line"><span class="comment">%反归一化</span></span><br><span class="line">trainoutput=mapminmax(<span class="string">'reverse'</span>,normtrainoutput,ts);</span><br><span class="line">validateoutput=mapminmax(<span class="string">'reverse'</span>,normvalidateoutput,ts);</span><br><span class="line">testoutput=mapminmax(<span class="string">'reverse'</span>,normtestoutput,ts);</span><br><span class="line"><span class="comment">%真实数据</span></span><br><span class="line">trainvalue=mapminmax(<span class="string">'reverse'</span>,trainsample.t,ts);<span class="comment">%正常的训练数据</span></span><br><span class="line">validatevalue=mapminmax(<span class="string">'reverse'</span>,valsample.t,ts);<span class="comment">%正常的验证的数据</span></span><br><span class="line">testvalue=mapminmax(<span class="string">'reverse'</span>,testsample.t,ts);<span class="comment">%正常的测试数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%plotregression拟合图</span></span><br><span class="line">tolvalue=[trainvalue validatevalue testvalue];</span><br><span class="line">toloutput=[trainoutput validateoutput testoutput];</span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">plotregression(trainvalue,trainoutput,<span class="string">'训练'</span>,validatevalue,validateoutput,<span class="string">'验证'</span>,...</span><br><span class="line">testvalue,testoutput,<span class="string">'测试'</span>,tolvalue,toloutput,<span class="string">'全体'</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>误差检验：</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">clear</span><br><span class="line">load net.mat</span><br><span class="line">e=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">6</span>);</span><br><span class="line">Z=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y1=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y2=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y3=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y4=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y5=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y6=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">1000</span></span><br><span class="line">    a=<span class="built_in">rand</span>(<span class="number">1</span>)*<span class="number">4</span>*<span class="built_in">pi</span><span class="number">-2</span>*<span class="built_in">pi</span>;</span><br><span class="line">    b=<span class="built_in">rand</span>(<span class="number">1</span>)*<span class="number">4</span>*<span class="built_in">pi</span><span class="number">-2</span>*<span class="built_in">pi</span>;</span><br><span class="line">    y1 = sim(net1,[a;b]);<span class="comment">%100样本三层10 5 1</span></span><br><span class="line">    y2 = sim(net2,[a;b]);<span class="comment">%100样本两层10 1</span></span><br><span class="line">    y3 = sim(net3,[a;b]);<span class="comment">%300样本两层10 1</span></span><br><span class="line">    y4 = sim(net4,[a;b]);<span class="comment">%500样本两层10 1</span></span><br><span class="line">    y5 = sim(net5,[a;b]);<span class="comment">%1000样本两层10 1</span></span><br><span class="line">    y6 = sim(net5,[a;b]);<span class="comment">%1000样本三层10 5 1</span></span><br><span class="line">    z=<span class="number">2</span>*a^<span class="number">2</span>+<span class="built_in">sin</span>(b+<span class="built_in">pi</span>/<span class="number">4</span>);</span><br><span class="line">    Z(<span class="built_in">i</span>)=z;Y1(<span class="built_in">i</span>)=y1;Y2(<span class="built_in">i</span>)=y2;Y3(<span class="built_in">i</span>)=y3;Y4(<span class="built_in">i</span>)=y4;Y5(<span class="built_in">i</span>)=y5;Y6(<span class="built_in">i</span>)=y6;</span><br><span class="line">    e(<span class="built_in">i</span>,:)=[z-y1 z-y2 z-y3 z-y4 z-y5 z-y6];</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">[std(e(:,<span class="number">1</span>)) std(e(:,<span class="number">2</span>)) std(e(:,<span class="number">3</span>)) std(e(:,<span class="number">4</span>)) std(e(:,<span class="number">5</span>)) std(e(:,<span class="number">6</span>))]</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y1,<span class="string">'net1'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y2,<span class="string">'net2'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y3,<span class="string">'net3'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y4,<span class="string">'net4'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y5,<span class="string">'net5'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y6,<span class="string">'net6'</span>);</span><br><span class="line"><span class="comment">%一次运行结果 43.5757    0.6526    0.0305    0.4823    0.2029    0.2029</span></span><br></pre></td></tr></table></figure>
<p><strong>（3）生成训练样本的子函数</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[Input,Output]</span> = <span class="title">GetInput</span><span class="params">(SampleNum)</span></span></span><br><span class="line">Input=<span class="built_in">zeros</span>(<span class="number">2</span>,SampleNum);</span><br><span class="line">Output=<span class="built_in">zeros</span>(<span class="number">1</span>,SampleNum);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:SampleNum</span><br><span class="line">    x=<span class="built_in">rand</span>(<span class="number">1</span>)*<span class="number">4</span>*<span class="built_in">pi</span><span class="number">-2</span>*<span class="built_in">pi</span>;</span><br><span class="line">    y=<span class="built_in">rand</span>(<span class="number">1</span>)*<span class="number">4</span>*<span class="built_in">pi</span><span class="number">-2</span>*<span class="built_in">pi</span>;</span><br><span class="line">    z=<span class="number">2</span>*x^<span class="number">2</span>+<span class="built_in">sin</span>(y+<span class="built_in">pi</span>/<span class="number">4</span>);</span><br><span class="line">    Input(:,<span class="built_in">i</span>)=[x,y];</span><br><span class="line">    Output(<span class="built_in">i</span>)=z;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><strong>（4）训练得到的网络</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%见net.mat</span></span><br></pre></td></tr></table></figure>
<p>本文之前发表在CSDN上，链接如下：<a target="_blank" rel="noopener" href="https://blog.csdn.net/Ricardo1998/article/details/109275013">原文地址</a></p>
</p></p></p></p></p></p>
        
      
      <!-- 
        <p>大三智能控制课程大作业，基于matlab的神经网络简单实现与训练</p>
<span id="more"></span>
<p><strong>实验目的</strong>：自己设计一个BP网络实现非线性函数映射</p>
<p><strong>基本要求</strong>：设有两输入单输出函数 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.781ex" xmlns="http://www.w3.org/2000/svg" width="26.35ex" height="2.667ex" role="img" focusable="false" viewBox="0 -833.9 11646.7 1178.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(939,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1511,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1955.7,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2445.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3112.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(4168.2,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="msup" transform="translate(4668.2,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(5899,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(6899.2,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(7368.2,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7713.2,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(8313.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(8702.2,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(9414.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mfrac" transform="translate(10414.7,0)"><g data-mml-node="mi" transform="translate(220,394) scale(0.707)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mn" transform="translate(244.7,-345) scale(0.707)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><rect width="603.1" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(11257.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p>
<p>其中自变量x,y的取值范围为 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="9.368ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4140.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(389,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1167,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(1667,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mo" transform="translate(2237,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(2681.7,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(3181.7,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mo" transform="translate(3751.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span> 试设计一个BP网络实现此函数映射。要求以完整的实验报告形式描述网络的结构、学习过程、结果，以附录形式附源程序。</p>
<h1 id="一网络结构">一、网络结构</h1>
<p>首先建立简单的BP神经网络模型，隐层神经元个数为10，输入二维，为函数的两个自变量x和y，输出为函数值的估计值，为一维。</p>
<p align="middle">
<img src="https://img-blog.csdnimg.cn/20201025162310427.png#pic_center" alt="在这里插入图片描述">
<p>
<p>在此基础上建立三层BP神经网络，两个隐层神经元个数都为10，输入二维，为函数的两个自变量x和y，输出为函数值的估计值，为一维。</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20201025162321314.png#pic_center" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<h1 id="二学习过程">二、学习过程</h1>
<p>使用自己编写的子函数GetInput生成训练数据，可以自行指定生成的数据个数。调用格式为：[Input,Output] = GetInput(SampleNum)</p>
<p><strong>（1）首先尝试自己通过编程实现简单的BP网络</strong></p>
<p>参数设置为： 总体样本30个，其中训练样本21个，验证样本5个，测试样本4个。 最多训练次数为10000次，允许误差选为10-7，学习速率为0.01。 传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="5.42ex" height="1.783ex" role="img" focusable="false" viewBox="0 -583 2395.6 788"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（purelin）最简单的一一对应关系。 训练算法为梯度下降法，不断地对权值矩阵W1、W2，阈值矩阵B1、B2进行修正，最终达到训练效果。</p>
<p><strong>（2）利用matlab自带的神经网络工具箱搭建BP网络</strong></p>
<p>备注：也尝试了GUI界面编程，但是无法以代码形式展现，其工作过程与命令行操作相同。 一共构建了两个网络：10-10-1和10-1，即第一部分中提到的两个网络。 网络10-10-1参数设置为： 总体样本分别为100个和1000个，其中训练样本70%，验证样本15%，测试样本15%。 最多训练次数为10000次，允许误差选为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex" xmlns="http://www.w3.org/2000/svg" width="4.495ex" height="2.02ex" role="img" focusable="false" viewBox="0 -871.1 1986.7 893.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(1033,393.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path></g></g></g></g></g></svg></mjx-container></span>，学习速率为0.01，动量因子为0.9。 隐层传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.912ex" xmlns="http://www.w3.org/2000/svg" width="9.571ex" height="3.052ex" role="img" focusable="false" viewBox="0 -946.2 4230.4 1349.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1823.6,0)"><g data-mml-node="mrow" transform="translate(220,398) scale(0.707)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1278,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(1278,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,289) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g><rect width="2166.9" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span>（tansig），输出层传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="5.42ex" height="1.783ex" role="img" focusable="false" viewBox="0 -583 2395.6 788"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（purelin）。 训练算法为神经网络训练中常用的L-M算法（trainlm） 网络10-1参数设置为： 总体样本分别为100个、300个、500个和1000个，其中训练样本70%，验证样本15%，测试样本15%。 最多训练次数为10000次，允许误差选为10-7，学习速率为0.01，动量因子为0.9。 隐层传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.912ex" xmlns="http://www.w3.org/2000/svg" width="9.571ex" height="3.052ex" role="img" focusable="false" viewBox="0 -946.2 4230.4 1349.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(1823.6,0)"><g data-mml-node="mrow" transform="translate(220,398) scale(0.707)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1278,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msup" transform="translate(1278,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,289) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g><rect width="2166.9" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span>（tansig），输出层传输函数为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex" xmlns="http://www.w3.org/2000/svg" width="5.42ex" height="1.783ex" role="img" focusable="false" viewBox="0 -583 2395.6 788"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1823.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></span>（purelin）。 训练算法为神经网络训练中常用的L-M算法（trainlm）</p>
<h1 id="三学习结果">三、学习结果</h1>
<p><strong>（1）自己编程搭建的BP神经网络</strong></p>
<figure>
<img src="https://img-blog.csdnimg.cn/2020102516303332.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY2FyZG8xOTk4,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<p align="middle">
30个训练样本和30个随机样本的验证结果
<p>
<figure>
<img src="https://img-blog.csdnimg.cn/2020102516304276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY2FyZG8xOTk4,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<p align="middle">
网络学习结果拟合图
<p>
<p><strong>（2）神经网络工具箱搭建的BP网络</strong></p>
Net1：10-10-1，100个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027171950127.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027172006947.png" width="300" height="400"></p>
</div>
Net2：10-1，100个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027172449308.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027172459865.png" width="300" height="400"></p>
</div>
Net3：10-1，300个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173107415.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027173107328.png" width="300" height="400"></p>
</div>
Net4：10-1，500个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173145314.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027173145225.png" width="300" height="400"></p>
</div>
Net5：10-1，1000个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173221576.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027173221470.png" width="300" height="400"></p>
</div>
Net6：10-10-1，1000个样本
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173302575.png" width="400" height="400"> <img src="https://img-blog.csdnimg.cn/20201027173302432.png" width="300" height="400"></p>
</div>
<h1 id="四误差分析">四、误差分析</h1>
<p><strong>（1）自己编程搭建的BP神经网络</strong></p>
<p>标准差：3.5937</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20201027173531832.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JpY2FyZG8xOTk4,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<p><strong>（2）神经网络工具箱搭建的BP网络</strong></p>
标准差：<br>
40.4614 / 0.8592 / 0.0310 0.5113 / 0.2013 / 0.2013
<div>
<p><img src="https://img-blog.csdnimg.cn/20201027173720713.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720724.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720720.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720712.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720740.png" width="300" height="300"> <img src="https://img-blog.csdnimg.cn/20201027173720739.png" width="300" height="300"></p>
</div>
<h1 id="五实验总结">五、实验总结</h1>
<p>这次实验中，我先尝试使用matlab自己编写了BP神经网络，输入映射函数使用最简单的y=x，训练算法采用梯度下降法。在实际操作中我发现当训练样本数大于28时，极有可能会陷入局部最优解，导致神经网络误差偏大，当训练样本数大于57时，误差甚至会随着迭代次数的增加而发散，这也是最基础的神经网络中难以避免的问题。20多个训练样本是比较合适的，所以总样本数选取了30。在训练样本和随机样本的检测下都显示出了比较好的效果。最后误差检验的结果显示，拟合图比较均匀地分布在直线两侧，标准差也不算太大。 由于经典梯度下降法有着各种各样的问题，我在调用神经网络工具箱时采用了现在普遍使用的L-M算法，同时也尝试搭建了三层的BP神经网络。在两层神经网络中，预测精度得到了明显的提高，而且随着训练样本的增加，精度也有提高的趋势。然而事情也并非绝对，在精度达到一个阈值时，即使增加样本，精度也不会有明显的提高。而且训练有着一定的偶然性，即使样本数很少，初始条件选择合适的话也会比样本数多的模型精度更高。而三层网络在训练样本数少时预测效果反而没有两层的好，当样本数较多时效果和两层模型相同，这也提醒我，当问题比较简单时，不要贸然增加网络深度，有时候网络过深也不见得是一件好事。</p>
<h1 id="附录源程序">附录（源程序）</h1>
<p><strong>（1）自编 训练函数：</strong> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% function main()</span></span><br><span class="line">clc                          <span class="comment">% 清屏</span></span><br><span class="line">clear all;                  <span class="comment">%清除内存以便加快运算速度</span></span><br><span class="line">close all;                  <span class="comment">%关闭当前所有figure图像</span></span><br><span class="line">Num=<span class="number">30</span>;                   <span class="comment">%所有样本总个数</span></span><br><span class="line">TrainSamNum=<span class="number">0.7</span>*Num;              <span class="comment">%输入样本数量为21</span></span><br><span class="line">ValSamNum=<span class="number">1</span>/<span class="number">6</span>*Num;               <span class="comment">%验证样本数量为5</span></span><br><span class="line">TestSamNum=<span class="number">2</span>/<span class="number">15</span>*Num;              <span class="comment">%测试样本数量也是4</span></span><br><span class="line">HiddenUnitNum=<span class="number">10</span>;            <span class="comment">%中间层隐节点数量取10</span></span><br><span class="line">InDim=<span class="number">2</span>;                    <span class="comment">%网络输入维度为2</span></span><br><span class="line">OutDim=<span class="number">1</span>;                   <span class="comment">%网络输出维度为1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%原始数据 </span></span><br><span class="line">[p,t] = GetInput(Num);<span class="comment">%生成输出p和输入t</span></span><br><span class="line"><span class="comment">%输入数据矩阵p</span></span><br><span class="line"><span class="comment">%目标数据矩阵t</span></span><br><span class="line">[SamIn,minp,maxp,SamOut,mint,maxt]=premnmx(p,t); <span class="comment">%原始样本对（输入和输出）初始化,进行了数据的归一化</span></span><br><span class="line">[TrainSamIn,ValSamIn,TestSamIn] =divideblock(SamIn,<span class="number">0.7</span>,<span class="number">1</span>/<span class="number">6</span>,<span class="number">2</span>/<span class="number">15</span>);</span><br><span class="line">[TrainSamOut,ValSamOut,TestSamOut] =divideblock(SamOut,<span class="number">0.7</span>,<span class="number">1</span>/<span class="number">6</span>,<span class="number">2</span>/<span class="number">15</span>);</span><br><span class="line"><span class="built_in">rand</span>(<span class="string">'state'</span>,sum(<span class="number">100</span>*clock))   <span class="comment">%依据系统时钟种子产生随机数         </span></span><br><span class="line">NoiseVar=<span class="number">0.01</span>;                    <span class="comment">%噪声强度为0.01（添加噪声的目的是为了防止网络过度拟合）</span></span><br><span class="line">Noise=NoiseVar*<span class="built_in">randn</span>(<span class="number">1</span>,TrainSamNum);   <span class="comment">%生成噪声</span></span><br><span class="line">TrainSamOut=TrainSamOut + Noise;                   <span class="comment">%将噪声添加到输出样本上</span></span><br><span class="line"></span><br><span class="line">MaxEpochs=<span class="number">10000</span>;                              <span class="comment">%最多训练次数为10000</span></span><br><span class="line">lr=<span class="number">0.01</span>;                                      <span class="comment">%学习速率为0.01</span></span><br><span class="line">E0=<span class="number">1e-7</span>;                                      <span class="comment">%目标误差为1e-7</span></span><br><span class="line">W1=<span class="number">0.5</span>*<span class="built_in">rand</span>(HiddenUnitNum,InDim)<span class="number">-0.1</span>;   <span class="comment">%初始化输入层与隐含层之间的权值</span></span><br><span class="line">B1=<span class="number">0.5</span>*<span class="built_in">rand</span>(HiddenUnitNum,<span class="number">1</span>)<span class="number">-0.1</span>;       <span class="comment">%初始化输入层与隐含层之间的阈值</span></span><br><span class="line">W2=<span class="number">0.5</span>*<span class="built_in">rand</span>(OutDim,HiddenUnitNum)<span class="number">-0.1</span>; <span class="comment">%初始化输出层与隐含层之间的权值              </span></span><br><span class="line">B2=<span class="number">0.5</span>*<span class="built_in">rand</span>(OutDim,<span class="number">1</span>)<span class="number">-0.1</span>;                <span class="comment">%初始化输出层与隐含层之间的阈值</span></span><br><span class="line">W11=W1;W22=W2;B11=B1;B22=B2;</span><br><span class="line"></span><br><span class="line">ErrHistory=[];                              <span class="comment">%给中间变量预先占据内存</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:MaxEpochs</span><br><span class="line">    </span><br><span class="line">    HiddenOut=logsig(W1*TrainSamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,TrainSamNum)); <span class="comment">% 隐含层网络输出</span></span><br><span class="line">    NetworkOut=W2*HiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,TrainSamNum);    <span class="comment">% 输出层网络输出</span></span><br><span class="line">    Error=TrainSamOut-NetworkOut;                       <span class="comment">% 实际输出与网络输出之差</span></span><br><span class="line">    SSE=sumsqr(Error);                               <span class="comment">%能量函数（误差平方和）</span></span><br><span class="line"></span><br><span class="line">    ErrHistory=[ErrHistory SSE];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> SSE&lt;E0,<span class="keyword">break</span>, <span class="keyword">end</span>      <span class="comment">%如果达到误差要求则跳出学习循环</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 下面是权值（阈值）依据能量函数负梯度下降原理所作的每一步动态调整量</span></span><br><span class="line">    Delta2=Error;</span><br><span class="line">    Delta1=W2'*Delta2.*HiddenOut.*(<span class="number">1</span>-HiddenOut);    </span><br><span class="line"></span><br><span class="line">    dW2=Delta2*HiddenOut';</span><br><span class="line">    dB2=Delta2*<span class="built_in">ones</span>(TrainSamNum,<span class="number">1</span>);</span><br><span class="line">    </span><br><span class="line">    dW1=Delta1*TrainSamIn';</span><br><span class="line">    dB1=Delta1*<span class="built_in">ones</span>(TrainSamNum,<span class="number">1</span>);</span><br><span class="line">    <span class="comment">%对输出层与隐含层之间的权值和阈值进行修正</span></span><br><span class="line">    W2=W2+lr*dW2;</span><br><span class="line">    B2=B2+lr*dB2;</span><br><span class="line">    <span class="comment">%对输入层与隐含层之间的权值和阈值进行修正</span></span><br><span class="line">    W1=W1+lr*dW1;</span><br><span class="line">    B1=B1+lr*dB1;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">SSE   <span class="comment">%显示最终误差</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%拟合图</span></span><br><span class="line">TrainHiddenOut=logsig(W1*TrainSamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,TrainSamNum)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">TrainNetworkOut=W2*TrainHiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,TrainSamNum);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">Trainoutput=postmnmx(TrainNetworkOut,mint,maxt);               <span class="comment">% 还原网络输出层的结果</span></span><br><span class="line">ValHiddenOut=logsig(W1*ValSamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,ValSamNum)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">ValNetworkOut=W2*ValHiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,ValSamNum);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">Valoutput=postmnmx(ValNetworkOut,mint,maxt);               <span class="comment">% 还原网络输出层的结果</span></span><br><span class="line">TestHiddenOut=logsig(W1*TestSamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,TestSamNum)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">TestNetworkOut=W2*TestHiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,TestSamNum);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">Testoutput=postmnmx(TestNetworkOut,mint,maxt);               <span class="comment">% 还原网络输出层的结果</span></span><br><span class="line">[TrainSamOut,ValSamOut,TestSamOut] =divideblock(t,<span class="number">0.7</span>,<span class="number">1</span>/<span class="number">6</span>,<span class="number">2</span>/<span class="number">15</span>); <span class="comment">%还原原始输出</span></span><br><span class="line">Tolvalue=[TrainSamOut,ValSamOut,TestSamOut];</span><br><span class="line">Toloutput=[Trainoutput Valoutput Testoutput];</span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">plotregression(TrainSamOut,Trainoutput,<span class="string">'训练'</span>,ValSamOut,Valoutput,<span class="string">'验证'</span>,...</span><br><span class="line">    TestSamOut,Testoutput,<span class="string">'测试'</span>,Tolvalue,Toloutput,<span class="string">'全体'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">%绘制网络输出与真实输出的对比图</span></span><br><span class="line">HiddenOut=logsig(W1*SamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,Num)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">NetworkOut=W2*HiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,Num);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">newk=postmnmx(NetworkOut,mint,maxt);               </span><br><span class="line">x=<span class="number">1</span>:Num; </span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>);<span class="built_in">plot</span>(x,newk,<span class="string">'r-o'</span>,x,t,<span class="string">'b--+'</span>)    <span class="comment">%绘对比图；</span></span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'网络输出'</span>,<span class="string">'实际输出'</span>);</span><br><span class="line">title(<span class="string">'训练样本的预测结果'</span>)</span><br><span class="line">[p1,t1] = GetInput(Num);<span class="comment">%生成检验的输出p1和输入t1</span></span><br><span class="line">[SamIn1,minp,maxp]=premnmx(p1);<span class="comment">%归一化</span></span><br><span class="line">HiddenOut=logsig(W1*SamIn1+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,Num)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">NetworkOut=W2*HiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,Num);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">newk1=postmnmx(NetworkOut,mint,maxt);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>);<span class="built_in">plot</span>(x,newk1,<span class="string">'r-o'</span>,x,t1,<span class="string">'b--+'</span>)    <span class="comment">%绘对比图；</span></span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'网络输出'</span>,<span class="string">'实际输出'</span>);</span><br><span class="line">title(<span class="string">'随机验证的预测结果'</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>误差检验：</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[p,t] = GetInput(<span class="number">1000</span>);<span class="comment">%生成输出p和输入t</span></span><br><span class="line">[SamIn,minp,maxp,tn,mint,maxt]=premnmx(p,t); <span class="comment">%原始样本对（输入和输出）初始化,进行了数据的归一化</span></span><br><span class="line">HiddenOut=logsig(W1*SamIn+<span class="built_in">repmat</span>(B1,<span class="number">1</span>,<span class="number">1000</span>)); <span class="comment">% 隐含层输出最终结果</span></span><br><span class="line">NetworkOut=W2*HiddenOut+<span class="built_in">repmat</span>(B2,<span class="number">1</span>,<span class="number">1000</span>);    <span class="comment">% 输出层输出最终结果</span></span><br><span class="line">newk=postmnmx(NetworkOut,mint,maxt);               </span><br><span class="line"><span class="built_in">figure</span>;plotregression(t,newk,<span class="string">'自编函数'</span>)</span><br><span class="line">E = t-newk;</span><br><span class="line">std(E)</span><br><span class="line"><span class="comment">% 一次运行结果：3.5937</span></span><br></pre></td></tr></table></figure>
<p><strong>（2）神经网络工具箱 训练函数：</strong> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">clear all</span><br><span class="line">[p,t] = GetInput(<span class="number">30</span>);<span class="comment">%生成输出p和输入t</span></span><br><span class="line">[p1,ps]=mapminmax(p);<span class="comment">%归一化</span></span><br><span class="line">[t1,ts]=mapminmax(t);</span><br><span class="line"><span class="comment">%分割为训练数据、验证数据、测试数据</span></span><br><span class="line">[trainsample.p,valsample.p,testsample.p] =divideblock(p,<span class="number">0.7</span>,<span class="number">0.15</span>,<span class="number">0.15</span>);</span><br><span class="line">[trainsample.t,valsample.t,testsample.t] =divideblock(t,<span class="number">0.7</span>,<span class="number">0.15</span>,<span class="number">0.15</span>);</span><br><span class="line"><span class="comment">%关于net函数的参数说明：net = newff(minmax(p),[隐层的神经元的个数，输出层的神经元的个数],...</span></span><br><span class="line"><span class="comment">% {隐层神经元的传输函数，输出层的传输函数｝,'反向传播的训练函数'),其中p为输入数据，t为输出数据</span></span><br><span class="line">TF1=<span class="string">'tansig'</span>;TF2=<span class="string">'purelin'</span>;</span><br><span class="line">net=newff(minmax(p),[<span class="number">10</span>,<span class="number">1</span>],{TF1 TF2},<span class="string">'trainlm'</span>);<span class="comment">%创建BP神经网络，隐层10个神经元，两层（不包括输入层）</span></span><br><span class="line"><span class="comment">%训练算法为Levenberg-Marquardt算法</span></span><br><span class="line"><span class="comment">%网络参数的设置</span></span><br><span class="line">net.trainParam.epochs=<span class="number">10000</span>;<span class="comment">%训练次数</span></span><br><span class="line">net.trainParam.goal=<span class="number">1e-7</span>;<span class="comment">%训练精度</span></span><br><span class="line">net.trainParam.lr=<span class="number">0.01</span>;<span class="comment">%学习率</span></span><br><span class="line">net.trainParam.mc=<span class="number">0.9</span>;<span class="comment">%动量因子</span></span><br><span class="line">net.trainParam.show=<span class="number">25</span>;<span class="comment">%显示间隔次数</span></span><br><span class="line">[net,tr]=train(net,trainsample.p,trainsample.t);<span class="comment">%训练网络</span></span><br><span class="line"><span class="comment">%计算仿真</span></span><br><span class="line">[normtrainoutput,trainPerf]=sim(net,trainsample.p,[],[],trainsample.t);<span class="comment">%训练的数据经BP得到的结果</span></span><br><span class="line">[normvalidateoutput,validatePerf]=sim(net,valsample.p,[],[],valsample.t);<span class="comment">%验证的数据经BP得到的结果</span></span><br><span class="line">[normtestoutput,testPerf]=sim(net,testsample.p,[],[],testsample.t);<span class="comment">%测试数据经BP得到的结果</span></span><br><span class="line"><span class="comment">%反归一化</span></span><br><span class="line">trainoutput=mapminmax(<span class="string">'reverse'</span>,normtrainoutput,ts);</span><br><span class="line">validateoutput=mapminmax(<span class="string">'reverse'</span>,normvalidateoutput,ts);</span><br><span class="line">testoutput=mapminmax(<span class="string">'reverse'</span>,normtestoutput,ts);</span><br><span class="line"><span class="comment">%真实数据</span></span><br><span class="line">trainvalue=mapminmax(<span class="string">'reverse'</span>,trainsample.t,ts);<span class="comment">%正常的训练数据</span></span><br><span class="line">validatevalue=mapminmax(<span class="string">'reverse'</span>,valsample.t,ts);<span class="comment">%正常的验证的数据</span></span><br><span class="line">testvalue=mapminmax(<span class="string">'reverse'</span>,testsample.t,ts);<span class="comment">%正常的测试数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%plotregression拟合图</span></span><br><span class="line">tolvalue=[trainvalue validatevalue testvalue];</span><br><span class="line">toloutput=[trainoutput validateoutput testoutput];</span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">plotregression(trainvalue,trainoutput,<span class="string">'训练'</span>,validatevalue,validateoutput,<span class="string">'验证'</span>,...</span><br><span class="line">testvalue,testoutput,<span class="string">'测试'</span>,tolvalue,toloutput,<span class="string">'全体'</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>误差检验：</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">clear</span><br><span class="line">load net.mat</span><br><span class="line">e=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">6</span>);</span><br><span class="line">Z=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y1=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y2=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y3=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y4=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y5=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line">Y6=<span class="built_in">zeros</span>(<span class="number">1000</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">1000</span></span><br><span class="line">    a=<span class="built_in">rand</span>(<span class="number">1</span>)*<span class="number">4</span>*<span class="built_in">pi</span><span class="number">-2</span>*<span class="built_in">pi</span>;</span><br><span class="line">    b=<span class="built_in">rand</span>(<span class="number">1</span>)*<span class="number">4</span>*<span class="built_in">pi</span><span class="number">-2</span>*<span class="built_in">pi</span>;</span><br><span class="line">    y1 = sim(net1,[a;b]);<span class="comment">%100样本三层10 5 1</span></span><br><span class="line">    y2 = sim(net2,[a;b]);<span class="comment">%100样本两层10 1</span></span><br><span class="line">    y3 = sim(net3,[a;b]);<span class="comment">%300样本两层10 1</span></span><br><span class="line">    y4 = sim(net4,[a;b]);<span class="comment">%500样本两层10 1</span></span><br><span class="line">    y5 = sim(net5,[a;b]);<span class="comment">%1000样本两层10 1</span></span><br><span class="line">    y6 = sim(net5,[a;b]);<span class="comment">%1000样本三层10 5 1</span></span><br><span class="line">    z=<span class="number">2</span>*a^<span class="number">2</span>+<span class="built_in">sin</span>(b+<span class="built_in">pi</span>/<span class="number">4</span>);</span><br><span class="line">    Z(<span class="built_in">i</span>)=z;Y1(<span class="built_in">i</span>)=y1;Y2(<span class="built_in">i</span>)=y2;Y3(<span class="built_in">i</span>)=y3;Y4(<span class="built_in">i</span>)=y4;Y5(<span class="built_in">i</span>)=y5;Y6(<span class="built_in">i</span>)=y6;</span><br><span class="line">    e(<span class="built_in">i</span>,:)=[z-y1 z-y2 z-y3 z-y4 z-y5 z-y6];</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">[std(e(:,<span class="number">1</span>)) std(e(:,<span class="number">2</span>)) std(e(:,<span class="number">3</span>)) std(e(:,<span class="number">4</span>)) std(e(:,<span class="number">5</span>)) std(e(:,<span class="number">6</span>))]</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y1,<span class="string">'net1'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y2,<span class="string">'net2'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y3,<span class="string">'net3'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y4,<span class="string">'net4'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y5,<span class="string">'net5'</span>);</span><br><span class="line"><span class="built_in">figure</span>;plotregression(Z,Y6,<span class="string">'net6'</span>);</span><br><span class="line"><span class="comment">%一次运行结果 43.5757    0.6526    0.0305    0.4823    0.2029    0.2029</span></span><br></pre></td></tr></table></figure>
<p><strong>（3）生成训练样本的子函数</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[Input,Output]</span> = <span class="title">GetInput</span><span class="params">(SampleNum)</span></span></span><br><span class="line">Input=<span class="built_in">zeros</span>(<span class="number">2</span>,SampleNum);</span><br><span class="line">Output=<span class="built_in">zeros</span>(<span class="number">1</span>,SampleNum);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:SampleNum</span><br><span class="line">    x=<span class="built_in">rand</span>(<span class="number">1</span>)*<span class="number">4</span>*<span class="built_in">pi</span><span class="number">-2</span>*<span class="built_in">pi</span>;</span><br><span class="line">    y=<span class="built_in">rand</span>(<span class="number">1</span>)*<span class="number">4</span>*<span class="built_in">pi</span><span class="number">-2</span>*<span class="built_in">pi</span>;</span><br><span class="line">    z=<span class="number">2</span>*x^<span class="number">2</span>+<span class="built_in">sin</span>(y+<span class="built_in">pi</span>/<span class="number">4</span>);</span><br><span class="line">    Input(:,<span class="built_in">i</span>)=[x,y];</span><br><span class="line">    Output(<span class="built_in">i</span>)=z;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><strong>（4）训练得到的网络</strong></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%见net.mat</span></span><br></pre></td></tr></table></figure>
<p>本文之前发表在CSDN上，链接如下：<a target="_blank" rel="noopener" href="https://blog.csdn.net/Ricardo1998/article/details/109275013">原文地址</a></p>
</p></p></p></p></p></p>
       -->
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/05/30/%E5%80%92%E7%AB%8B%E6%91%86%E7%9A%84%E6%A8%A1%E7%B3%8A%E6%8E%A7%E5%88%B6%E5%AE%9E%E9%AA%8C%EF%BC%88%E5%9F%BA%E4%BA%8Ematlab-simulink%E4%BB%BF%E7%9C%9F%EF%BC%89/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          倒立摆的模糊控制实验（基于matlab-simulink仿真）
        
      </div>
    </a>
  
  
    <a href="/2020/05/08/%E6%88%91%E7%9A%84%E6%8A%97%E7%96%AB%E6%95%85%E4%BA%8B%E8%AE%B0%E8%BF%B0%E6%8A%A5%E5%91%8A/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">“我的抗疫故事”记述报告</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>


<div class="ds-share share" data-thread-key="利用BP网络实现非线性函数映射（基于matlab工具箱）" data-title="利用BP网络实现非线性函数映射（基于matlab工具箱）" data-url="https://renzehua1998.github.io/2020/05/28/%E5%88%A9%E7%94%A8BP%E7%BD%91%E7%BB%9C%E5%AE%9E%E7%8E%B0%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0%E6%98%A0%E5%B0%84%EF%BC%88%E5%9F%BA%E4%BA%8Ematlab%E5%B7%A5%E5%85%B7%E7%AE%B1%EF%BC%89/"  data-images="/img/avatar.jpeg" data-content="利用BP网络实现非线性函数映射（基于matlab工具箱）">
    <div class="ds-share-inline">
      <!-- <ul  class="ds-share-icons-16">
      	<li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
        <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
        <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
        <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
        <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>
      </ul> -->
      <!-- <div class="ds-share-icons-more">
      </div> -->
    </div>
 </div>
 





  <section id="comments" class="comments">
    <style>
      .comments{margin:30px;padding:10px;}
      @media screen and (max-width:800px){.comments{margin:auto;padding:10px;}}
    </style>
    <!-- <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script> -->
<!-- 上一个cdn也挂了,换成网上找的这一个 -->

<script src="/js/av-min.js"></script>


<script src="/js/Valine.min.js"></script>


<div id="vcomment" class="comment"></div> 
<script>
    var notify = 'true' == true ? true : false;
    var verify = 'false' == true ? true : false;
    window.onload = function() {
        new Valine({
            el: '#vcomment',
            notify: notify,
            verify: verify,
            app_id: "aRj0IyORTJLLeGJu8NCvPFIX-gzGzoHsz",
            app_key: "pLwQN2GAclg4a0tNAzc3VqLP",
            placeholder: "因为开发版云服务器存在休眠的可能，可以多评论一次以便我尽快收到哦~\n您也可以选择留下邮箱，收到回复后会及时发邮件通知您",
            avatar:"monsterid",
            requiredFields: "nick,mail".split(',')
        });
    }
</script>
</section>




  <!--  修改 开始位置-->

<script src="/js/mermaid/mermaid.min.js"></script>
  <!-- 或者使用CDN -->
<script>
    $(document).ready(function() {
        var mermaid_config = {
            startOnLoad: true,
            theme: 'forest',
            flowchart:{
                useMaxWidth: false,
                htmlLabels: true
            }                
        }
        mermaid.initialize(mermaid_config);
    });
</script>   <!-- 修改 结束位置 --> 
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2022-2025 Zehua Ren
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/Renzehua1998/hexo-theme-magnificent" target="_blank">Magnificent</a>
        </div>
    </div>
  </div>
  
    <!-- <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->
    <!-- 官方cdn在第二次打开网页的时候次数统计会变成none，我把相关代码去掉了放在本地。 -->
    
<script src="/js/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">
            本站总访问量<span id="busuanzi_value_site_pv"></span>次
    </span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">
            您是第<span id="busuanzi_value_site_uv"></span>位访客
    </span>
  
</footer>
    </div>
    

<script>
	var yiliaConfig = {
		//mathjax: [object Object],
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}

	//是否开启动画
	if(yiliaConfig.animate === true){

		// require(['/js/jquery.lazyload.js'], function(){
		// 	//avatar
		// 	$(".js-avatar").attr("src", $(".js-avatar").attr("lazy-src"));
		// 	$(".js-avatar")[0].onload = function(){
		// 		$(".profilepic").addClass("show");
		// 	}
		// });

		if(yiliaConfig.isHome === true){
			//content
			function showArticle(){
				$(".article").each(function(){
					if( $(this).offset().top <= $(window).scrollTop()+$(window).height() && !($(this).hasClass('show')) ) {
						$(this).removeClass("hidden").addClass("show");
						$(this).addClass("is-hiddened");
					}else{
						if(!$(this).hasClass("is-hiddened")){
							$(this).addClass("hidden");
						}
					}
				});
			}
			$(window).on('scroll', function(){
				showArticle();
			});
			showArticle();
		}

	}

	//是否新窗口打开链接
	if(yiliaConfig.open_in_new == true){
		$(".article a[href]").attr("target", "_blank")
	}
</script>

<script src="/js/particles.js"></script>


<script src="/js/main.js"></script>




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>



<div id="progress" class="sidebutton" style="position:fixed;bottom:120px;right:0px;cursor: pointer;">
    <div class="progressbar">
        <div class="left-container">
            <div class="left-circle"></div>
        </div>
        <div class="right-container">
            <div class="right-circle"></div>
        </div>
    </div>
    <div id="progress-rate"
        title="浏览进度"
        style="color:#fff; font-size: 15px;text-align: center;padding-top: 8px;">
    </div>
</div>
<div id="changebg" class="sidebutton" style="position:fixed;bottom:70px;right:0px;cursor: pointer;">
    <a title="背景颜色"><img class="iconimg" src="/img/change.png"/></a>
</div>
<div id="totop" class="sidebutton" style="position:fixed;bottom:40px;right:0px;cursor: pointer;">
    <a title="返回顶部"><img class="iconimg" src="/img/scrollup.png"/></a>
</div>
<div id="todown" class="sidebutton" style="position:fixed;bottom:10px;right:0px;cursor: pointer;">
    <a title="到达底部"><img class="iconimg" src="/img/scrolldown.png"/></a>
</div>
<script src="/js/sidebutton.js"></script>
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/1koharu.model.json"},"display":{"position":"left","width":150,"height":300,"hOffset":50,"vOffset":-40},"mobile":{"show":false},"rect":"opacity:0.7","log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
<script>
  var hide = false;
  function myFunction(x) {
      x.classList.toggle("change");
      if(hide == false){
          $(".left-col").css('display', 'none');
          $(".mid-col").css("left", 6);
          $(".tools-col").css('display', 'none');
          $(".tools-col.hide").css('display', 'none');
          hide = true;
          $(".mymenucontainer").css('left', '0');
      }else{
          $(".left-col").css('display', '');
          $(".mid-col").css("left", 300);
          $(".tools-col").css('display', '');
          $(".tools-col.hide").css('display', '');
          hide = false;
          $(".mymenucontainer").css('left', '280px');
      }
  }
  if (localStorage.getItem('bright') === '1') {
    document.body.classList.add('bright');
  }
  // else if (new Date().getHours() >= 7 && new Date().getHours() < 22) {
  //   document.body.classList.add('bright');
  // }
  // else if (matchMedia('(prefers-color-scheme: light)').matches) {
  //   document.body.classList.add('bright');
  // }
</script>
</html>