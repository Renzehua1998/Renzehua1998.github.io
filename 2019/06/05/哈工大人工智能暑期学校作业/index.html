<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>哈工大人工智能暑期学校作业 | Zehua的个人博客</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="大二下暑假哈工大人工智能暑期学校《高性能机器学习》课程结课作业">
<meta property="og:type" content="article">
<meta property="og:title" content="哈工大人工智能暑期学校作业">
<meta property="og:url" content="https://renzehua1998.github.io/2019/06/05/%E5%93%88%E5%B7%A5%E5%A4%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9A%91%E6%9C%9F%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/index.html">
<meta property="og:site_name" content="Zehua的个人博客">
<meta property="og:description" content="大二下暑假哈工大人工智能暑期学校《高性能机器学习》课程结课作业">
<meta property="og:locale">
<meta property="article:published_time" content="2019-06-05T10:50:00.000Z">
<meta property="article:modified_time" content="2022-08-28T16:04:29.323Z">
<meta property="article:author" content="Zehua Ren">
<meta property="article:tag" content="选修课">
<meta property="article:tag" content="神经网络">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Zehua的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  

  
  <!-- 
<script src="/js/av-min.js"></script>
 -->
  <!-- <script src="//unpkg.com/leancloud-storage@3.15.0/dist/av-min.js"></script> -->
  <!-- 
<script src="/js/Valine.min.js"></script>
 -->
  <!-- <script src="//unpkg.com/valine/dist/Valine.min.js"></script> -->
  
  <!-- 
<script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
 -->
  <!-- 
<script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>
 -->
  <!-- 
<script src="/js/require.min.js"></script>
 -->
  
<script src="/js/jquery.min.js"></script>


  
      <!-- <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script> -->
<!-- 此CDN链接已失效，我找了很久的资源，从一个废弃GitHub仓库中找到了对应的js资源可以实现功能 -->
<!-- 由于av-core-mini-0.6.1.js和av-min.js冲突，所以把本位置和源文件的所有AV改成AV0以避免冲突 -->

<script src="/js/av-core-mini-0.6.1.js"></script>

<script>AV0.initialize("w1SO7gpilVpRbakyqOw3qll3-gzGzoHsz", "puuKUoPCcKHPTwmLvShbcaOi");</script>

<script src="/js/Counter.js"></script>

  
<meta name="generator" content="Hexo 6.1.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="mymenucontainer" title="侧栏按钮" onclick="myFunction(this)">
      <div class="bar1"></div>
      <div class="bar2"></div>
      <div class="bar3"></div>
    </div>    
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img src="/img/avatar.jpeg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						
							<div class="icon-wrap icon-ribbon hide" data-idx="1">
								<div class="searchicon"></div>
							</div>
						
						<div class="icon-wrap icon-ribbon hide" data-idx="2">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="3">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="4">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						
						<li>搜索</li>
						
						<li>标签</li>
						
						<li>友链</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		
		<!-- 原开关位置 -->
		
		<div>
			<input id="animation" type="checkbox" onclick="checkboxOnclick(this)"/>
			<a>特效开关</a>
		</div>
		
		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<!-- 单页面内标签位置 -->
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">时间线</a></li>
				        
							<li><a href="/categories">分类</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/Renzehua1998" title="github">github</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/ren-ze-hua-31" title="zhihu">zhihu</a>
					        
								<a class="CSDN" target="_blank" href="https://blog.csdn.net/Ricardo1998" title="CSDN">CSDN</a>
					        
								<a class="cnblogs" target="_blank" href="https://www.cnblogs.com/renzehua" title="cnblogs">cnblogs</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div id="js-search">
						
  <div class="form-group">
    <div class="search-delete" title="清除搜索框" onclick="deleteSearch()">
      <div class="search-bar1"></div>
      <div class="search-bar2"></div>
    </div>
    <input type="text" oninput="gotoSearch()" id="local-search-input" placeholder="在这里输入内容"/>
  </div>  
  <div id="local-search-result">
  </div>
  <div class="search-tags">
    <a href="/tags/CPP/" style="font-size: 10px;">CPP</a> <a href="/tags/CTF/" style="font-size: 10px;">CTF</a> <a href="/tags/C%E8%AF%AD%E8%A8%80/" style="font-size: 18.33px;">C语言</a> <a href="/tags/Julia/" style="font-size: 10.83px;">Julia</a> <a href="/tags/LabVIEW/" style="font-size: 13.33px;">LabVIEW</a> <a href="/tags/Python/" style="font-size: 16.67px;">Python</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/matlab/" style="font-size: 15.83px;">matlab</a> <a href="/tags/%E4%BC%98%E5%8C%96/" style="font-size: 12.5px;">优化</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 10px;">前端</a> <a href="/tags/%E5%9B%BE%E4%B8%8E%E7%BD%91%E7%BB%9C/" style="font-size: 14.17px;">图与网络</a> <a href="/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 11.67px;">图数据库</a> <a href="/tags/%E5%9B%BE%E8%AE%BA/" style="font-size: 13.33px;">图论</a> <a href="/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" style="font-size: 20px;">实验报告</a> <a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 10px;">密码学</a> <a href="/tags/%E6%80%81%E5%8A%BF%E6%84%9F%E7%9F%A5/" style="font-size: 11.67px;">态势感知</a> <a href="/tags/%E6%8E%A7%E5%88%B6/" style="font-size: 14.17px;">控制</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" style="font-size: 13.33px;">数据挖掘</a> <a href="/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/" style="font-size: 19.17px;">杂七杂八</a> <a href="/tags/%E6%AD%A3%E5%88%99/" style="font-size: 10px;">正则</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 12.5px;">神经网络</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 17.5px;">算法</a> <a href="/tags/%E8%81%9A%E7%B1%BB/" style="font-size: 11.67px;">聚类</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 15.83px;">计网</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 13.33px;">论文阅读</a> <a href="/tags/%E8%B6%85%E5%9B%BE/" style="font-size: 12.5px;">超图</a> <a href="/tags/%E9%80%89%E4%BF%AE%E8%AF%BE/" style="font-size: 12.5px;">选修课</a>
  </div>
  <script>
    function deleteSearch() {
      jQuery("#local-search-input").val('') // 清除搜索内容
      $(".search-tags").css('display', 'block'); // 显示隐藏设置
      $(".search-delete").css('display', 'none');
      let show = document.getElementById('local-search-result'); // 清除原搜索结果
      show.innerHTML=''
    }
    function gotoSearch() { // 执行函数（输入内容改变且不为空时执行搜索，为空时显示tags，隐藏清除按钮）
      let inputStr = jQuery("#local-search-input").val() // 获取输入内容
      if (inputStr !== "") {
        $(".search-tags").css('display', 'none');
        $(".search-delete").css('display', 'block');
        handleSearch(inputStr)
      } else {
        $(".search-tags").css('display', 'block');
        $(".search-delete").css('display', 'none');
        let show = document.getElementById('local-search-result'); // 清除原搜索结果
        show.innerHTML=''
      }
    }
    function handleSearch(inputStr) { // 实施搜索
      let data = JSON.parse(localStorage.getItem('content'))
      inputStr = inputStr.toLowerCase()
      data.forEach((post) => { // 搜索匹配字符串具体位置
        post.matchTitle = false
        post.titleIndex = post.title.toLowerCase().indexOf(inputStr)
        if (post.titleIndex > -1) {
	  			post.matchTitle = true
	  		}

        post.matchText = false
        post.textIndex = post.text.toLowerCase().indexOf(inputStr)
        if (post.textIndex > -1) {
          post.matchText = true
        }

        post.matchTags = false
	  		post.tags.forEach((tag) => {
	  			if (tag.name.toLowerCase().indexOf(inputStr) > -1) {
            post.matchTags = true
	      	}
	  		})
      });

      let htmlStr = '' // 搜索结果html
      htmlStr += '<ul class="search-ul">'
      findPost = false;
      data.forEach((post) => { // 生成展示结果
        if (post.matchTitle || post.matchText || post.matchTags) {
          findPost = true;
          let tagStr = '' // tags标签
          post.tags.forEach((tag) => {
            index = tag.name.toLowerCase().indexOf(inputStr)
            if (index > -1) {
              name = tag.name.slice(0,index)+'<b>'+tag.name.slice(index,index+inputStr.length)+'</b>'+tag.name.slice(index+inputStr.length)
            } else {
              name = tag.name
            }
            tagStr+='<span>#'+name+' </span>'
          })
          if(post.matchTitle) { // 标题
            title = post.title.slice(0,post.titleIndex)
            + '<b>' + post.title.slice(post.titleIndex, post.titleIndex+inputStr.length) + '</b>'
            + post.title.slice(post.titleIndex+inputStr.length)
          } else {
            title = post.title
          }
          if(post.matchText) { // 内容
            text = post.text.slice(post.textIndex-25,post.textIndex)
            + '<b>' + post.text.slice(post.textIndex, post.textIndex+inputStr.length) + '</b>'
            + post.text.slice(post.textIndex+inputStr.length,post.textIndex+inputStr.length+25)
          } else {
            text = post.text.slice(0,50)
          }
          htmlStr+='\
          <li class="search-li">\
            <a href="/'+post.path+'" class="search-title">\
              <span>'+title+'</span>\
            </a>\
            <p class="search-result">\
              '+text+'\
            </p>\
            <p class="search-time">\
              <span>'+post.date.slice(0,10)+'</span>\
            </p>\
            <p class="search-tag">\
              '+tagStr+'\
            </p>\
          </li>';
        }
      })
      if (!findPost) {
        htmlStr+='\
        <li class="search-li">\
          <p class="search-result">\
            没有搜索到相关结果，请清除内容重新搜索或清除浏览器缓存后重试。\
          </p>\
        <\li>'
      }
      htmlStr += '<ul>'
      let show = document.getElementById('local-search-result');
      show.innerHTML=htmlStr
    }
  </script>

					</div>
				</section>
				

				
				<section class="switch-part switch-part3">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/CPP/" style="font-size: 10px;">CPP</a> <a href="/tags/CTF/" style="font-size: 10px;">CTF</a> <a href="/tags/C%E8%AF%AD%E8%A8%80/" style="font-size: 18.33px;">C语言</a> <a href="/tags/Julia/" style="font-size: 10.83px;">Julia</a> <a href="/tags/LabVIEW/" style="font-size: 13.33px;">LabVIEW</a> <a href="/tags/Python/" style="font-size: 16.67px;">Python</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/matlab/" style="font-size: 15.83px;">matlab</a> <a href="/tags/%E4%BC%98%E5%8C%96/" style="font-size: 12.5px;">优化</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 10px;">前端</a> <a href="/tags/%E5%9B%BE%E4%B8%8E%E7%BD%91%E7%BB%9C/" style="font-size: 14.17px;">图与网络</a> <a href="/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 11.67px;">图数据库</a> <a href="/tags/%E5%9B%BE%E8%AE%BA/" style="font-size: 13.33px;">图论</a> <a href="/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" style="font-size: 20px;">实验报告</a> <a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 10px;">密码学</a> <a href="/tags/%E6%80%81%E5%8A%BF%E6%84%9F%E7%9F%A5/" style="font-size: 11.67px;">态势感知</a> <a href="/tags/%E6%8E%A7%E5%88%B6/" style="font-size: 14.17px;">控制</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" style="font-size: 13.33px;">数据挖掘</a> <a href="/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/" style="font-size: 19.17px;">杂七杂八</a> <a href="/tags/%E6%AD%A3%E5%88%99/" style="font-size: 10px;">正则</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 12.5px;">神经网络</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 17.5px;">算法</a> <a href="/tags/%E8%81%9A%E7%B1%BB/" style="font-size: 11.67px;">聚类</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 15.83px;">计网</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 13.33px;">论文阅读</a> <a href="/tags/%E8%B6%85%E5%9B%BE/" style="font-size: 12.5px;">超图</a> <a href="/tags/%E9%80%89%E4%BF%AE%E8%AF%BE/" style="font-size: 12.5px;">选修课</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part4">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://renzehua1998.github.io/">境外分流</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://renzehua.gitee.io/">国内分流</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://foreverblog.cn/go.html">虫洞</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://echos2019.github.io/Myblog">echos的博客</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://gwyxjtu.github.io">果果的博客</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://patorjk.com/software/taag">字符字母生成</a>
			        
			        </div>
				</section>
				

				
				<section class="switch-part switch-part5">
					<div id="js-aboutme">西北某高校系统工程硕士在读</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
<script>
	// 特效开关
	function checkboxOnclick(checkbox){
		if ( checkbox.checked){
			localStorage.setItem('noanimation','0');
			$(".live2d-widget-container").css('display', 'inline');  // live2d显示
			if (localStorage.getItem('bright') === '1') {
				var circlecolor={"value": ['#999']};
				var linecolor="#999";
				particlesJS0(circlecolor, linecolor);
			}else{
				var circlecolor={"value": ['#0fc', '#0ff', '#ccc', '#ffa500', '#7b5d5f', '#ff945c', '#cfb7c4']};
				var linecolor="#00bfff";
				particlesJS0(circlecolor, linecolor);
			}
		}else{
			localStorage.setItem('noanimation','1');
			$(".live2d-widget-container").css('display', 'none');  // live2d隐藏
			var canvas_el = document.querySelector('#particles-js > .particles-js-canvas-el');
			canvas_el.remove();  // 清除特效
		}
	}
	// 特效函数
	function particlesJS0(circlecolor, linecolor) {
		// require(['/js/particles.js'], function(particlesJS) {
			window.particlesJS('particles-js',

			{
				"particles": {
				"number": {
					"value": 80,
					"density": {
					"enable": true,
					"value_area": 800
					}
				},
				"color": circlecolor,
				"shape": {
					"type": "circle",
					"stroke": {
					"width": 0,
					"color": "#000000"
					},
					"polygon": {
					"nb_sides": 5
					},
					"image": {
					"src": "img/github.svg",
					"width": 100,
					"height": 100
					}
				},
				"opacity": {
					"value": 0.5,
					"random": false,
					"anim": {
					"enable": false,
					"speed": 1,
					"opacity_min": 0.1,
					"sync": false
					}
				},
				"size": {
					"value": 5,
					"random": true,
					"anim": {
					"enable": false,
					"speed": 40,
					"size_min": 0.1,
					"sync": false
					}
				},
				"line_linked": {
					"enable": true,
					"distance": 150,
					"color": linecolor,
					"opacity": 0.4,
					"width": 1
				},
				"move": {
					"enable": true,
					"speed": 6,
					"direction": "none",
					"random": false,
					"straight": false,
					"out_mode": "out",
					"attract": {
					"enable": false,
					"rotateX": 600,
					"rotateY": 1200
					}
				}
				},
				"interactivity": {
				"detect_on": "canvas",
				"events": {
					"onhover": {
					"enable": true,
					"mode": "repulse"
					},
					"onclick": {
					"enable": true,
					"mode": "push"
					},
					"resize": true
				},
				"modes": {
					"grab": {
					"distance": 400,
					"line_linked": {
						"opacity": 1
					}
					},
					"bubble": {
					"distance": 400,
					"size": 40,
					"duration": 2,
					"opacity": 8,
					"speed": 3
					},
					"repulse": {
					"distance": 200
					},
					"push": {
					"particles_nb": 4
					},
					"remove": {
					"particles_nb": 2
					}
				}
				},
				"retina_detect": true,
				"config_demo": {
				"hide_card": false,
				"background_color": "#b61924",
				"background_image": "",
				"background_position": "50% 50%",
				"background_repeat": "no-repeat",
				"background_size": "cover"
				}
			}

			);
		// })
	}
</script>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
		<!-- <div class="search-icon"></div> -->
		
		<p class="animation-info">特效：</p>
		<div id="animation-button" onclick="animOnclick()"></div>
		
  		<h1 class="header-author js-mobile-header hide"></h1>
  	</div>
	<!-- 
  <div class="form-group">
    <div class="search-delete" title="清除搜索框" onclick="deleteSearch()">
      <div class="search-bar1"></div>
      <div class="search-bar2"></div>
    </div>
    <input type="text" oninput="gotoSearch()" id="local-search-input" placeholder="在这里输入内容"/>
  </div>  
  <div id="local-search-result">
  </div>
  <div class="search-tags">
    <a href="/tags/CPP/" style="font-size: 10px;">CPP</a> <a href="/tags/CTF/" style="font-size: 10px;">CTF</a> <a href="/tags/C%E8%AF%AD%E8%A8%80/" style="font-size: 18.33px;">C语言</a> <a href="/tags/Julia/" style="font-size: 10.83px;">Julia</a> <a href="/tags/LabVIEW/" style="font-size: 13.33px;">LabVIEW</a> <a href="/tags/Python/" style="font-size: 16.67px;">Python</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/matlab/" style="font-size: 15.83px;">matlab</a> <a href="/tags/%E4%BC%98%E5%8C%96/" style="font-size: 12.5px;">优化</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 10px;">前端</a> <a href="/tags/%E5%9B%BE%E4%B8%8E%E7%BD%91%E7%BB%9C/" style="font-size: 14.17px;">图与网络</a> <a href="/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 11.67px;">图数据库</a> <a href="/tags/%E5%9B%BE%E8%AE%BA/" style="font-size: 13.33px;">图论</a> <a href="/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" style="font-size: 20px;">实验报告</a> <a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 10px;">密码学</a> <a href="/tags/%E6%80%81%E5%8A%BF%E6%84%9F%E7%9F%A5/" style="font-size: 11.67px;">态势感知</a> <a href="/tags/%E6%8E%A7%E5%88%B6/" style="font-size: 14.17px;">控制</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" style="font-size: 13.33px;">数据挖掘</a> <a href="/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/" style="font-size: 19.17px;">杂七杂八</a> <a href="/tags/%E6%AD%A3%E5%88%99/" style="font-size: 10px;">正则</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 12.5px;">神经网络</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 17.5px;">算法</a> <a href="/tags/%E8%81%9A%E7%B1%BB/" style="font-size: 11.67px;">聚类</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 15.83px;">计网</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 13.33px;">论文阅读</a> <a href="/tags/%E8%B6%85%E5%9B%BE/" style="font-size: 12.5px;">超图</a> <a href="/tags/%E9%80%89%E4%BF%AE%E8%AF%BE/" style="font-size: 12.5px;">选修课</a>
  </div>
  <script>
    function deleteSearch() {
      jQuery("#local-search-input").val('') // 清除搜索内容
      $(".search-tags").css('display', 'block'); // 显示隐藏设置
      $(".search-delete").css('display', 'none');
      let show = document.getElementById('local-search-result'); // 清除原搜索结果
      show.innerHTML=''
    }
    function gotoSearch() { // 执行函数（输入内容改变且不为空时执行搜索，为空时显示tags，隐藏清除按钮）
      let inputStr = jQuery("#local-search-input").val() // 获取输入内容
      if (inputStr !== "") {
        $(".search-tags").css('display', 'none');
        $(".search-delete").css('display', 'block');
        handleSearch(inputStr)
      } else {
        $(".search-tags").css('display', 'block');
        $(".search-delete").css('display', 'none');
        let show = document.getElementById('local-search-result'); // 清除原搜索结果
        show.innerHTML=''
      }
    }
    function handleSearch(inputStr) { // 实施搜索
      let data = JSON.parse(localStorage.getItem('content'))
      inputStr = inputStr.toLowerCase()
      data.forEach((post) => { // 搜索匹配字符串具体位置
        post.matchTitle = false
        post.titleIndex = post.title.toLowerCase().indexOf(inputStr)
        if (post.titleIndex > -1) {
	  			post.matchTitle = true
	  		}

        post.matchText = false
        post.textIndex = post.text.toLowerCase().indexOf(inputStr)
        if (post.textIndex > -1) {
          post.matchText = true
        }

        post.matchTags = false
	  		post.tags.forEach((tag) => {
	  			if (tag.name.toLowerCase().indexOf(inputStr) > -1) {
            post.matchTags = true
	      	}
	  		})
      });

      let htmlStr = '' // 搜索结果html
      htmlStr += '<ul class="search-ul">'
      findPost = false;
      data.forEach((post) => { // 生成展示结果
        if (post.matchTitle || post.matchText || post.matchTags) {
          findPost = true;
          let tagStr = '' // tags标签
          post.tags.forEach((tag) => {
            index = tag.name.toLowerCase().indexOf(inputStr)
            if (index > -1) {
              name = tag.name.slice(0,index)+'<b>'+tag.name.slice(index,index+inputStr.length)+'</b>'+tag.name.slice(index+inputStr.length)
            } else {
              name = tag.name
            }
            tagStr+='<span>#'+name+' </span>'
          })
          if(post.matchTitle) { // 标题
            title = post.title.slice(0,post.titleIndex)
            + '<b>' + post.title.slice(post.titleIndex, post.titleIndex+inputStr.length) + '</b>'
            + post.title.slice(post.titleIndex+inputStr.length)
          } else {
            title = post.title
          }
          if(post.matchText) { // 内容
            text = post.text.slice(post.textIndex-25,post.textIndex)
            + '<b>' + post.text.slice(post.textIndex, post.textIndex+inputStr.length) + '</b>'
            + post.text.slice(post.textIndex+inputStr.length,post.textIndex+inputStr.length+25)
          } else {
            text = post.text.slice(0,50)
          }
          htmlStr+='\
          <li class="search-li">\
            <a href="/'+post.path+'" class="search-title">\
              <span>'+title+'</span>\
            </a>\
            <p class="search-result">\
              '+text+'\
            </p>\
            <p class="search-time">\
              <span>'+post.date.slice(0,10)+'</span>\
            </p>\
            <p class="search-tag">\
              '+tagStr+'\
            </p>\
          </li>';
        }
      })
      if (!findPost) {
        htmlStr+='\
        <li class="search-li">\
          <p class="search-result">\
            没有搜索到相关结果，请清除内容重新搜索或清除浏览器缓存后重试。\
          </p>\
        <\li>'
      }
      htmlStr += '<ul>'
      let show = document.getElementById('local-search-result');
      show.innerHTML=htmlStr
    }
  </script>
 -->
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/avatar.jpeg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			</div>
			<hgroup>
			  <h1 class="header-author"></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">时间线</a></li>
		        
					<li><a href="/categories">分类</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Renzehua1998" title="github">github</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/ren-ze-hua-31" title="zhihu">zhihu</a>
			        
						<a class="CSDN" target="_blank" href="https://blog.csdn.net/Ricardo1998" title="CSDN">CSDN</a>
			        
						<a class="cnblogs" target="_blank" href="https://www.cnblogs.com/renzehua" title="cnblogs">cnblogs</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

<script>
	// 特效开关
	function animOnclick(){
		if (localStorage.getItem('noanimation') === '1'){
			$("#animation-button").attr('class','animation-off');
			localStorage.setItem('noanimation','0');
			if (localStorage.getItem('bright') === '1') {
				var circlecolor={"value": ['#999']};
				var linecolor="#999";
				particlesJS0(circlecolor, linecolor);
			}else{
				var circlecolor={"value": ['#0fc', '#0ff', '#ccc', '#ffa500', '#7b5d5f', '#ff945c', '#cfb7c4']};
				var linecolor="#00bfff";
				particlesJS0(circlecolor, linecolor);
			}
		}else{
			$("#animation-button").attr('class','animation-on');
			localStorage.setItem('noanimation','1');
			var canvas_el = document.querySelector('#particles-js > .particles-js-canvas-el');
			canvas_el.remove();  // 清除特效
		}
	}
	// 特效函数
	function particlesJS0(circlecolor, linecolor) {
		// require(['/js/particles.js'], function(particlesJS) {
			window.particlesJS('particles-js',

			{
				"particles": {
				"number": {
					"value": 80,
					"density": {
					"enable": true,
					"value_area": 800
					}
				},
				"color": circlecolor,
				"shape": {
					"type": "circle",
					"stroke": {
					"width": 0,
					"color": "#000000"
					},
					"polygon": {
					"nb_sides": 5
					},
					"image": {
					"src": "img/github.svg",
					"width": 100,
					"height": 100
					}
				},
				"opacity": {
					"value": 0.5,
					"random": false,
					"anim": {
					"enable": false,
					"speed": 1,
					"opacity_min": 0.1,
					"sync": false
					}
				},
				"size": {
					"value": 5,
					"random": true,
					"anim": {
					"enable": false,
					"speed": 40,
					"size_min": 0.1,
					"sync": false
					}
				},
				"line_linked": {
					"enable": true,
					"distance": 150,
					"color": linecolor,
					"opacity": 0.4,
					"width": 1
				},
				"move": {
					"enable": true,
					"speed": 6,
					"direction": "none",
					"random": false,
					"straight": false,
					"out_mode": "out",
					"attract": {
					"enable": false,
					"rotateX": 600,
					"rotateY": 1200
					}
				}
				},
				"interactivity": {
				"detect_on": "canvas",
				"events": {
					"onhover": {
					"enable": true,
					"mode": "repulse"
					},
					"onclick": {
					"enable": true,
					"mode": "push"
					},
					"resize": true
				},
				"modes": {
					"grab": {
					"distance": 400,
					"line_linked": {
						"opacity": 1
					}
					},
					"bubble": {
					"distance": 400,
					"size": 40,
					"duration": 2,
					"opacity": 8,
					"speed": 3
					},
					"repulse": {
					"distance": 200
					},
					"push": {
					"particles_nb": 4
					},
					"remove": {
					"particles_nb": 2
					}
				}
				},
				"retina_detect": true,
				"config_demo": {
				"hide_card": false,
				"background_color": "#b61924",
				"background_image": "",
				"background_position": "50% 50%",
				"background_repeat": "no-repeat",
				"background_size": "cover"
				}
			}

			);
		// })
	}
</script>
      <div class="body-wrap"><article id="post-哈工大人工智能暑期学校作业" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/06/05/%E5%93%88%E5%B7%A5%E5%A4%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9A%91%E6%9C%9F%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/" class="article-date">
  	<time datetime="2019-06-05T10:50:00.000Z" itemprop="datePublished">2019-06-05</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      哈工大人工智能暑期学校作业
      
    </h1>
  

        
          <div style="margin-top:10px;">
    <span class="post-time">
      <span class="post-meta-item-icon">
        <i class="fa fa-keyboard-o"></i>
        <span class="post-meta-item-text">  全文共: </span>
        <span class="post-count">2.3k字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
        <i class="fa fa-hourglass-half"></i>
        <span class="post-meta-item-text">  阅读时长: </span>
        <span class="post-count">14分</span>
      </span>
    </span>
</div>
        
      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%80%89%E4%BF%AE%E8%AF%BE/" rel="tag">选修课</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/">知识整理</a><a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/">本科课程</a><a class="article-category-link" href="/categories/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E4%BA%8C/">大二</a>
	</div>


        
          
<div class="counter-tag counter">
    <span id="/2019/06/05/%E5%93%88%E5%B7%A5%E5%A4%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9A%91%E6%9C%9F%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/" class="leancloud_visitors post-title-link"
          style="font-size: 12px" data-flag-title="哈工大人工智能暑期学校作业">
         &nbsp;
        阅读
    </span>
</div>

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
          <!-- Table of Contents -->

          <!-- version1 -->
          <!-- 
            <div id="toc" class="toc-article">
            <strong class="toc-title">文章目录</strong>
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#summary-of-the-paper"><span class="toc-number">1.</span> <span class="toc-text">1.Summary of the paper</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#main-problems-motivation"><span class="toc-number">1.1.</span> <span class="toc-text">(1)Main problems &amp; motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#method-the-authors-used"><span class="toc-number">1.2.</span> <span class="toc-text">(2)Method the authors used</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#the-experimental-settings"><span class="toc-number">1.3.</span> <span class="toc-text">(3)The experimental settings</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#a-brief-summary-of-the-findings-of-the-work"><span class="toc-number">1.4.</span> <span class="toc-text">(4)A brief summary of the findings of the work</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#advantages-of-the-methodsystem-compared-to-other-alternative-methods"><span class="toc-number">2.</span> <span class="toc-text">2.Advantages of the method&#x2F;system compared to other alternative methods</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#the-limitations-of-the-methodsystem"><span class="toc-number">3.</span> <span class="toc-text">3.The limitations of the method&#x2F;system</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#possible-improvements"><span class="toc-number">4.</span> <span class="toc-text">4.Possible improvements</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#references"><span class="toc-number">5.</span> <span class="toc-text">REFERENCES</span></a></li></ol>
            </div>
           -->

          <!-- version2 -->
          
            <p class="show-toc-btn" id="show-toc-btn" onclick="showToc();">
            <strong class="btn-text">文章导航</strong>
            </p>
            <div id="toc-article" class="toc-article" style="display:none">
                <span id="toc-close" class="toc-close" title="隐藏导航" onclick="showBtn();">×</span>
                <strong class="toc-title">文章目录</strong>
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#summary-of-the-paper"><span class="toc-number">1.</span> <span class="toc-text">1.Summary of the paper</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#main-problems-motivation"><span class="toc-number">1.1.</span> <span class="toc-text">(1)Main problems &amp; motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#method-the-authors-used"><span class="toc-number">1.2.</span> <span class="toc-text">(2)Method the authors used</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#the-experimental-settings"><span class="toc-number">1.3.</span> <span class="toc-text">(3)The experimental settings</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#a-brief-summary-of-the-findings-of-the-work"><span class="toc-number">1.4.</span> <span class="toc-text">(4)A brief summary of the findings of the work</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#advantages-of-the-methodsystem-compared-to-other-alternative-methods"><span class="toc-number">2.</span> <span class="toc-text">2.Advantages of the method&#x2F;system compared to other alternative methods</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#the-limitations-of-the-methodsystem"><span class="toc-number">3.</span> <span class="toc-text">3.The limitations of the method&#x2F;system</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#possible-improvements"><span class="toc-number">4.</span> <span class="toc-text">4.Possible improvements</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#references"><span class="toc-number">5.</span> <span class="toc-text">REFERENCES</span></a></li></ol>
            </div>
            <script type="text/javascript">
              function showToc(){
                  var toc_article = document.getElementById("toc-article");
                  var show_toc_btn = document.getElementById("show-toc-btn");
                  toc_article.setAttribute("style","display:block");
                  show_toc_btn.setAttribute("style","display:none");
                  };
              function showBtn(){
                  var toc_article = document.getElementById("toc-article");
                  var show_toc_btn = document.getElementById("show-toc-btn");
                  toc_article.setAttribute("style","display:none");
                  show_toc_btn.setAttribute("style","display:block");
                  };
            </script>
          
          <p>大二下暑假哈工大人工智能暑期学校《高性能机器学习》课程结课作业</p>
<span id="more"></span>
<center>
Report on Paper “Adaptive Deep Reuse: Accelerating CNN Training on the Fly”
</center>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/8731452">参考文章链接</a></p>
<h1 id="summary-of-the-paper">1.Summary of the paper</h1>
<h2 id="main-problems-motivation">(1)Main problems &amp; motivation</h2>
<p>This paper raises a method called “Adaptive Deep Reuse” in CNN training mainly to avoid the unnecessary calculation. As the experimental results show, in real operation of CNN training, there are many similarities among the images. The repetition of the same calculation will significantly cost lots of time and resources. If we can reuse the same calculation results, we will save a huge amount of unnecessary calculation and improve the time of CNN training. The mainly point is how to efficiently find the similar items. But there are also other points we should concern. We know that CNN training includes two kinds of propagations: forward and backward, they have some different method in training period. And as most people concerned, the accuracy of the result is also needed to be noticed in the training period. In addition, the new method must be suitable to most of the conditions we might face in real training. So how to find the same or similar neural vectors; whether the method of adaptive deep reuse useful in the backward propagation; how to reduce the errors and save time in this new training method; and how to make this method useful in different conditions of Convolution Neural Networks is the main questions this paper tries to solve.</p>
<h2 id="method-the-authors-used">(2)Method the authors used</h2>
<p>i.How to find the same or similar neural vectors As above, we notice that there are many similarities among the images and the neural vectors. The most direct method we can think of is clustering. But the paper doesn’t use the commonest clustering method: k-means. We use another clustering method called: LSH(Locality-Sensitive Hashing). We define a parameter called “remain ratio”, which uses the number of the remain group to divide the original number of the neural vectors. This parameter describes the clustering level. Then we use a function which contains a random vector (v) to measure the input (x), if v·x&gt;0, the result is 1, else the result is 0. We use several random vectors to form a gather of vector, when we calculate the v·x one-by-one, we will be able to get a bit vector called “ID”, just as the ID number of the neuron vector. If two of the vectors’ “ID” are same, we call them in a same cluster. From this method, we can find the similar neural vectors. The range of clustering can of course be different. We use three range of clustering to suit different situations: single-input level, single-batch level and across-batch level. ii.Whether the method of adaptive deep reuse useful in the backward propagation As we know, the backward propagation takes 2/3 of the whole training period. It is important to prove that the method we developed in part 1 is suitable for the backward propagation. If the answer is yes, we can use this method in both of two propagations and save a huge amount of calculations. There is a very simple rule we have learned before, which is called “chain rule”. That is, in a direct way, a method to determine the derivative of complex function. We have this kind of function during the forward propagation: y=x·W+b, when we do the backward propagation, we must solve two results: Weight Gradient (the weight’s partial respect to the loss function) and the input’s partial respect to the loss function. By using the chain rule, we can get the results we want, so we prove that the new method is useful in the backward propagation. iii.How to reduce the errors and save time in this new training method There is a common rule in natural word: we can’t have our cake and eat it. Reducing errors and saving time are two part that we cannot achieve the best at the same time. As the paper writes, although the time complexity of this new method can achieve a pretty low level, the accuracy also get lower. So we should make a decision on whether reduce the calculations or increase the accuracy of the new method. If we have a better equipment to do this training, the computation overhead might not be concerned, then we can achieve both of the two goals. So while training, based on our hardware, we can make a trade-off between accuracy and the computation overhead. iv.How to make this method useful in different conditions of CNN The paper comes up with two strategies to make this method suitable for different models of CNN. For the first one, we try to make sure that at beginning, the length (L) of the sub-vector is as large as possible, and the number of hashing functions (H) is as small as possible. But still make sure that the errors is acceptable. While in the end, let L be the as large as we can and H be as small as we can. In this way, we can save many unnecessary calculations at the beginning, and get the much accurate result in the end. There must be some rules set to make sure that the “L” and “H” are suitable during the training. And when to change them is also a important thing we should considered. We choose the exact time that when the loss function get it’s lowest point to change the parameters of “L” and “H”. The paper also set some limitations to guarantee that it makes shorter time cost and more accurate result. The second strategy is simpler than the first one. We use the parameter “CR” to express if we choose reuse or not. When CR=1, it shows that we use reuse, and when it comes to 0, it shows we don’t use it. During the training period, “L” and “H” do not change any more. We choose the suitable value of L and H, and set CR=1 at first. When the loss function achieves its lowest point, we let CR=0 and train it again.</p>
<h2 id="the-experimental-settings">(3)The experimental settings</h2>
<p>From the paper, the authors choose three different networks called: CifarNet, AlexNet and VGG-19. Their ranges of layers and the datasets they used are different. Firstly, we test the similarity of the neural vectors, the result shows that all of them have a huge number of similarities, so we can use the deep reuse method to simplify the training period. We also find that the smaller the clustering granularity is, the more similarities we might find among the vectors, while it will cost more calculation overhead. To study each parameters’ influence on the results we use control variable method. The paper finds that when the remain ratio (rc) and H don’t change, the smaller the L is, the higher accuracy the result get. When L do not change, the larger the H is, the higher accuracy the result get and rc get larger, but it will also cause more calculations. And CR=1 (reuse the neural vectors) cost less calculations than CR=0, while the accuracy get shorter. The strategies we use as above may get different conditions. We test three strategies, the first strategy is that we don’t change the parameters of “L” and ”H”, the second strategy is that we change L and H to adapt the training period, the third strategy is the second one in (2) iv. The result is that the second one can get more time saving than the third one, and the first one is less than the other strategies.</p>
<h2 id="a-brief-summary-of-the-findings-of-the-work">(4)A brief summary of the findings of the work</h2>
<p>Through this paper, the authors come up with a new method called adaptive deep reuse. This new method can significantly save the similar calculation through finding the similar neural vectors. They use LSH to find the similar vectors and reuse the same calculation results. They also prove that this method can also be used in the backward propagation. Then they optimize the strategy of choosing the parameters. Then they design several experiments to prove that this new method can significantly speed up the CNN training period.</p>
<h1 id="advantages-of-the-methodsystem-compared-to-other-alternative-methods">2.Advantages of the method/system compared to other alternative methods</h1>
<p>This paper come up with a new method to optimize the structure of CNN. In the past research, people always focus on the weight redundancy, and try to reduce the calculation in the convolutional layers. While this paper tries to reduce the calculation at a much earlier time: the input layer (the input picture or the activation map). By using this, we can reduce a huge amount of calculations at a very early time. Some research use rounding to reduce the calculation[1], although this method won’t reduce the accuracy of the final classification result, this method will cause unpredictable mistakes during training, which is uncontrollable. If we have to make a more accurate result, this method will not be suitable. This paper reuse the similar items in the input layer, can control the errors by define the parameter of “L”, ”H” and ”CR”. It gives us a pretty controllable way to limit the errors according to our demand. Another research also uses hashing[2] like this paper. They using hashing in the convolutional layers, that is also effective, but compared to this paper, the method doesn’t save the repetitive calculations at the very beginning, which will also cause time waste. The other study focus on reduce the superfluous weight, it is useful to save time because there are plenty of unnecessary weight among the neural networks, if we can remove them, the speed of training will of course raises. But this method had a shortcoming: the backward propagation (BP) is very complexed, and we should develop some extra strategies to solve this problem. [3] In this paper, we prove that this method can also be used in the BP problems. So we will save many energy by not focus on the extra strategies in solving the BP problems. Many researches use the sparsity of the layers to reduce the unnecessary calculations, but this method require a very sparse activation map. When it becomes complexed these methods will not be able to simplify the training period. So the method this paper uses is more general than those methods in this aspect.</p>
<h1 id="the-limitations-of-the-methodsystem">3.The limitations of the method/system</h1>
<p>There are four main method to solve this problem[4]: Network pruning and thinning, Tensor decomposition, knowledge transfer and Fine module design. We know that there are many redundant parameters in convolutional layers and fully connected layers. The adaptive deep reuse method cannot remove these redundant parameters, it can just simplify the similar calculations at a very early stage. But it doesn’t come up with a method to solve pruning. In this method, we have to make a trade-off between accuracy and the computation overhead. The more accurate results we make, the more computational expense we should pay. We can’t reduce the calculation and reduce the errors at the same time. It is the limitation caused by the neural network itself. This paper only focuses on reducing the calculation of each iteration, don’t pay attention to reduce the iterations number. It’s true that in reuse we can only reduce the calculation in only one iteration. This is the limitation of the method itself. Only if the input layer must have many similarities that this method can be more effective. If the input become complexed, in another word, don’t have many similar parts, the adaptive deep reuse will not be able to take advantages than other methods.</p>
<h1 id="possible-improvements">4.Possible improvements</h1>
<p>We can see that the adaptive deep reuse can save much computational expense, but it still has limitations. The first limitation is that it cannot remove the redundant parameters. We can add some extra strategies to it when the training comes to the convolutional layers and fully connected layers. This method can make the simplify of the training further. The author mentions another method: enforcing a low-rank structure on the layers. This method is different from the method in this paper. Maybe we can combine two of them to make a better one. The clash between accuracy and the computation overhead limits our training on the neural network. We can select the parameters more rational so that both of them can achieve an ideal level. But the clash still exists, the only thing we can do is making it smaller. We don’t focus on reducing the iterations number of the network. Maybe next time we can add some other method like large-batch data parallelism, importance sampling, etc. For many conditions the inputs have a huge amount of similarities, so we don’t have to worry about the limitation of the inputs. But when we really face with this situation, we can use some other method to treat this picture, then pick out the main information in it.</p>
<h1 id="references">REFERENCES</h1>
<p>[1] S. Gupta, A. Agrawal, K. Gopalakrishnan, and P. Narayanan, “Deeplearning with limited numerical precision,” inInternational Conferenceon Machine Learning, 2015, pp. 1737–1746. [2] [6] R. Spring and A. Shrivastava, “Scalable and sustainable deep learningvia randomized hashing,” inProceedings of the 23rd ACM SIGKDDInternational Conference on Knowledge Discovery and Data Mining.ACM, 2017, pp. 445–454. [3] S. V. Kamarthi and S. Pittner, “Accelerating neural network trainingusing weight extrapolations,”Neural networks, vol. 12, no. 9, pp. 1285–1299, 1999. [4] LIN Jing-Dong, WU Xin-Yi, CHAI Yi, YIN Hong-Peng. Structure Optimization of Convolutional NeuralNetworks: A Survey.Acta Automatica Sinica, 2019,XX(X): X−X</p>

        
      
      <!-- 
        <p>大二下暑假哈工大人工智能暑期学校《高性能机器学习》课程结课作业</p>
<span id="more"></span>
<center>
Report on Paper “Adaptive Deep Reuse: Accelerating CNN Training on the Fly”
</center>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/8731452">参考文章链接</a></p>
<h1 id="summary-of-the-paper">1.Summary of the paper</h1>
<h2 id="main-problems-motivation">(1)Main problems &amp; motivation</h2>
<p>This paper raises a method called “Adaptive Deep Reuse” in CNN training mainly to avoid the unnecessary calculation. As the experimental results show, in real operation of CNN training, there are many similarities among the images. The repetition of the same calculation will significantly cost lots of time and resources. If we can reuse the same calculation results, we will save a huge amount of unnecessary calculation and improve the time of CNN training. The mainly point is how to efficiently find the similar items. But there are also other points we should concern. We know that CNN training includes two kinds of propagations: forward and backward, they have some different method in training period. And as most people concerned, the accuracy of the result is also needed to be noticed in the training period. In addition, the new method must be suitable to most of the conditions we might face in real training. So how to find the same or similar neural vectors; whether the method of adaptive deep reuse useful in the backward propagation; how to reduce the errors and save time in this new training method; and how to make this method useful in different conditions of Convolution Neural Networks is the main questions this paper tries to solve.</p>
<h2 id="method-the-authors-used">(2)Method the authors used</h2>
<p>i.How to find the same or similar neural vectors As above, we notice that there are many similarities among the images and the neural vectors. The most direct method we can think of is clustering. But the paper doesn’t use the commonest clustering method: k-means. We use another clustering method called: LSH(Locality-Sensitive Hashing). We define a parameter called “remain ratio”, which uses the number of the remain group to divide the original number of the neural vectors. This parameter describes the clustering level. Then we use a function which contains a random vector (v) to measure the input (x), if v·x&gt;0, the result is 1, else the result is 0. We use several random vectors to form a gather of vector, when we calculate the v·x one-by-one, we will be able to get a bit vector called “ID”, just as the ID number of the neuron vector. If two of the vectors’ “ID” are same, we call them in a same cluster. From this method, we can find the similar neural vectors. The range of clustering can of course be different. We use three range of clustering to suit different situations: single-input level, single-batch level and across-batch level. ii.Whether the method of adaptive deep reuse useful in the backward propagation As we know, the backward propagation takes 2/3 of the whole training period. It is important to prove that the method we developed in part 1 is suitable for the backward propagation. If the answer is yes, we can use this method in both of two propagations and save a huge amount of calculations. There is a very simple rule we have learned before, which is called “chain rule”. That is, in a direct way, a method to determine the derivative of complex function. We have this kind of function during the forward propagation: y=x·W+b, when we do the backward propagation, we must solve two results: Weight Gradient (the weight’s partial respect to the loss function) and the input’s partial respect to the loss function. By using the chain rule, we can get the results we want, so we prove that the new method is useful in the backward propagation. iii.How to reduce the errors and save time in this new training method There is a common rule in natural word: we can’t have our cake and eat it. Reducing errors and saving time are two part that we cannot achieve the best at the same time. As the paper writes, although the time complexity of this new method can achieve a pretty low level, the accuracy also get lower. So we should make a decision on whether reduce the calculations or increase the accuracy of the new method. If we have a better equipment to do this training, the computation overhead might not be concerned, then we can achieve both of the two goals. So while training, based on our hardware, we can make a trade-off between accuracy and the computation overhead. iv.How to make this method useful in different conditions of CNN The paper comes up with two strategies to make this method suitable for different models of CNN. For the first one, we try to make sure that at beginning, the length (L) of the sub-vector is as large as possible, and the number of hashing functions (H) is as small as possible. But still make sure that the errors is acceptable. While in the end, let L be the as large as we can and H be as small as we can. In this way, we can save many unnecessary calculations at the beginning, and get the much accurate result in the end. There must be some rules set to make sure that the “L” and “H” are suitable during the training. And when to change them is also a important thing we should considered. We choose the exact time that when the loss function get it’s lowest point to change the parameters of “L” and “H”. The paper also set some limitations to guarantee that it makes shorter time cost and more accurate result. The second strategy is simpler than the first one. We use the parameter “CR” to express if we choose reuse or not. When CR=1, it shows that we use reuse, and when it comes to 0, it shows we don’t use it. During the training period, “L” and “H” do not change any more. We choose the suitable value of L and H, and set CR=1 at first. When the loss function achieves its lowest point, we let CR=0 and train it again.</p>
<h2 id="the-experimental-settings">(3)The experimental settings</h2>
<p>From the paper, the authors choose three different networks called: CifarNet, AlexNet and VGG-19. Their ranges of layers and the datasets they used are different. Firstly, we test the similarity of the neural vectors, the result shows that all of them have a huge number of similarities, so we can use the deep reuse method to simplify the training period. We also find that the smaller the clustering granularity is, the more similarities we might find among the vectors, while it will cost more calculation overhead. To study each parameters’ influence on the results we use control variable method. The paper finds that when the remain ratio (rc) and H don’t change, the smaller the L is, the higher accuracy the result get. When L do not change, the larger the H is, the higher accuracy the result get and rc get larger, but it will also cause more calculations. And CR=1 (reuse the neural vectors) cost less calculations than CR=0, while the accuracy get shorter. The strategies we use as above may get different conditions. We test three strategies, the first strategy is that we don’t change the parameters of “L” and ”H”, the second strategy is that we change L and H to adapt the training period, the third strategy is the second one in (2) iv. The result is that the second one can get more time saving than the third one, and the first one is less than the other strategies.</p>
<h2 id="a-brief-summary-of-the-findings-of-the-work">(4)A brief summary of the findings of the work</h2>
<p>Through this paper, the authors come up with a new method called adaptive deep reuse. This new method can significantly save the similar calculation through finding the similar neural vectors. They use LSH to find the similar vectors and reuse the same calculation results. They also prove that this method can also be used in the backward propagation. Then they optimize the strategy of choosing the parameters. Then they design several experiments to prove that this new method can significantly speed up the CNN training period.</p>
<h1 id="advantages-of-the-methodsystem-compared-to-other-alternative-methods">2.Advantages of the method/system compared to other alternative methods</h1>
<p>This paper come up with a new method to optimize the structure of CNN. In the past research, people always focus on the weight redundancy, and try to reduce the calculation in the convolutional layers. While this paper tries to reduce the calculation at a much earlier time: the input layer (the input picture or the activation map). By using this, we can reduce a huge amount of calculations at a very early time. Some research use rounding to reduce the calculation[1], although this method won’t reduce the accuracy of the final classification result, this method will cause unpredictable mistakes during training, which is uncontrollable. If we have to make a more accurate result, this method will not be suitable. This paper reuse the similar items in the input layer, can control the errors by define the parameter of “L”, ”H” and ”CR”. It gives us a pretty controllable way to limit the errors according to our demand. Another research also uses hashing[2] like this paper. They using hashing in the convolutional layers, that is also effective, but compared to this paper, the method doesn’t save the repetitive calculations at the very beginning, which will also cause time waste. The other study focus on reduce the superfluous weight, it is useful to save time because there are plenty of unnecessary weight among the neural networks, if we can remove them, the speed of training will of course raises. But this method had a shortcoming: the backward propagation (BP) is very complexed, and we should develop some extra strategies to solve this problem. [3] In this paper, we prove that this method can also be used in the BP problems. So we will save many energy by not focus on the extra strategies in solving the BP problems. Many researches use the sparsity of the layers to reduce the unnecessary calculations, but this method require a very sparse activation map. When it becomes complexed these methods will not be able to simplify the training period. So the method this paper uses is more general than those methods in this aspect.</p>
<h1 id="the-limitations-of-the-methodsystem">3.The limitations of the method/system</h1>
<p>There are four main method to solve this problem[4]: Network pruning and thinning, Tensor decomposition, knowledge transfer and Fine module design. We know that there are many redundant parameters in convolutional layers and fully connected layers. The adaptive deep reuse method cannot remove these redundant parameters, it can just simplify the similar calculations at a very early stage. But it doesn’t come up with a method to solve pruning. In this method, we have to make a trade-off between accuracy and the computation overhead. The more accurate results we make, the more computational expense we should pay. We can’t reduce the calculation and reduce the errors at the same time. It is the limitation caused by the neural network itself. This paper only focuses on reducing the calculation of each iteration, don’t pay attention to reduce the iterations number. It’s true that in reuse we can only reduce the calculation in only one iteration. This is the limitation of the method itself. Only if the input layer must have many similarities that this method can be more effective. If the input become complexed, in another word, don’t have many similar parts, the adaptive deep reuse will not be able to take advantages than other methods.</p>
<h1 id="possible-improvements">4.Possible improvements</h1>
<p>We can see that the adaptive deep reuse can save much computational expense, but it still has limitations. The first limitation is that it cannot remove the redundant parameters. We can add some extra strategies to it when the training comes to the convolutional layers and fully connected layers. This method can make the simplify of the training further. The author mentions another method: enforcing a low-rank structure on the layers. This method is different from the method in this paper. Maybe we can combine two of them to make a better one. The clash between accuracy and the computation overhead limits our training on the neural network. We can select the parameters more rational so that both of them can achieve an ideal level. But the clash still exists, the only thing we can do is making it smaller. We don’t focus on reducing the iterations number of the network. Maybe next time we can add some other method like large-batch data parallelism, importance sampling, etc. For many conditions the inputs have a huge amount of similarities, so we don’t have to worry about the limitation of the inputs. But when we really face with this situation, we can use some other method to treat this picture, then pick out the main information in it.</p>
<h1 id="references">REFERENCES</h1>
<p>[1] S. Gupta, A. Agrawal, K. Gopalakrishnan, and P. Narayanan, “Deeplearning with limited numerical precision,” inInternational Conferenceon Machine Learning, 2015, pp. 1737–1746. [2] [6] R. Spring and A. Shrivastava, “Scalable and sustainable deep learningvia randomized hashing,” inProceedings of the 23rd ACM SIGKDDInternational Conference on Knowledge Discovery and Data Mining.ACM, 2017, pp. 445–454. [3] S. V. Kamarthi and S. Pittner, “Accelerating neural network trainingusing weight extrapolations,”Neural networks, vol. 12, no. 9, pp. 1285–1299, 1999. [4] LIN Jing-Dong, WU Xin-Yi, CHAI Yi, YIN Hong-Peng. Structure Optimization of Convolutional NeuralNetworks: A Survey.Acta Automatica Sinica, 2019,XX(X): X−X</p>

       -->
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/09/23/%E7%94%B5%E5%AD%90%E7%BA%BF%E8%B7%AF%E8%AE%BE%E8%AE%A1%E4%B8%8A%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A1/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          电子线路设计上实验报告1
        
      </div>
    </a>
  
  
    <a href="/2019/06/05/Python%E9%80%89%E4%BF%AE%E8%AF%BE/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Python选修课大作业</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>


<div class="ds-share share" data-thread-key="哈工大人工智能暑期学校作业" data-title="哈工大人工智能暑期学校作业" data-url="https://renzehua1998.github.io/2019/06/05/%E5%93%88%E5%B7%A5%E5%A4%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9A%91%E6%9C%9F%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/"  data-images="/img/avatar.jpeg" data-content="哈工大人工智能暑期学校作业">
    <div class="ds-share-inline">
      <!-- <ul  class="ds-share-icons-16">
      	<li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
        <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
        <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
        <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
        <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>
      </ul> -->
      <!-- <div class="ds-share-icons-more">
      </div> -->
    </div>
 </div>
 





  <section id="comments" class="comments">
    <style>
      .comments{margin:30px;padding:10px;}
      @media screen and (max-width:800px){.comments{margin:auto;padding:10px;}}
    </style>
    <!-- <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script> -->
<!-- 上一个cdn也挂了,换成网上找的这一个 -->

<script src="/js/av-min.js"></script>


<script src="/js/Valine.min.js"></script>


<div id="vcomment" class="comment"></div> 
<script>
    var notify = 'true' == true ? true : false;
    var verify = 'false' == true ? true : false;
    window.onload = function() {
        new Valine({
            el: '#vcomment',
            notify: notify,
            verify: verify,
            app_id: "aRj0IyORTJLLeGJu8NCvPFIX-gzGzoHsz",
            app_key: "pLwQN2GAclg4a0tNAzc3VqLP",
            placeholder: "因为开发版云服务器存在休眠的可能，可以多评论一次以便我尽快收到哦~\n您也可以选择留下邮箱，收到回复后会及时发邮件通知您",
            avatar:"monsterid",
            requiredFields: "nick,mail".split(',')
        });
    }
</script>
</section>




  <!--  修改 开始位置-->

<script src="/js/mermaid/mermaid.min.js"></script>
  <!-- 或者使用CDN -->
<script>
    $(document).ready(function() {
        var mermaid_config = {
            startOnLoad: true,
            theme: 'forest',
            flowchart:{
                useMaxWidth: false,
                htmlLabels: true
            }                
        }
        mermaid.initialize(mermaid_config);
    });
</script>   <!-- 修改 结束位置 --> 
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2022-2025 Zehua Ren
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/Renzehua1998/hexo-theme-magnificent" target="_blank">Magnificent</a>
        </div>
    </div>
  </div>
  
    <!-- <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->
    <!-- 官方cdn在第二次打开网页的时候次数统计会变成none，我把相关代码去掉了放在本地。 -->
    
<script src="/js/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">
            本站总访问量<span id="busuanzi_value_site_pv"></span>次
    </span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">
            您是第<span id="busuanzi_value_site_uv"></span>位访客
    </span>
  
</footer>
    </div>
    

<script>
	var yiliaConfig = {
		//mathjax: [object Object],
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}

	//是否开启动画
	if(yiliaConfig.animate === true){

		// require(['/js/jquery.lazyload.js'], function(){
		// 	//avatar
		// 	$(".js-avatar").attr("src", $(".js-avatar").attr("lazy-src"));
		// 	$(".js-avatar")[0].onload = function(){
		// 		$(".profilepic").addClass("show");
		// 	}
		// });

		if(yiliaConfig.isHome === true){
			//content
			function showArticle(){
				$(".article").each(function(){
					if( $(this).offset().top <= $(window).scrollTop()+$(window).height() && !($(this).hasClass('show')) ) {
						$(this).removeClass("hidden").addClass("show");
						$(this).addClass("is-hiddened");
					}else{
						if(!$(this).hasClass("is-hiddened")){
							$(this).addClass("hidden");
						}
					}
				});
			}
			$(window).on('scroll', function(){
				showArticle();
			});
			showArticle();
		}

	}

	//是否新窗口打开链接
	if(yiliaConfig.open_in_new == true){
		$(".article a[href]").attr("target", "_blank")
	}
</script>

<script src="/js/particles.js"></script>


<script src="/js/main.js"></script>




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>



<div id="progress" class="sidebutton" style="position:fixed;bottom:120px;right:0px;cursor: pointer;">
    <div class="progressbar">
        <div class="left-container">
            <div class="left-circle"></div>
        </div>
        <div class="right-container">
            <div class="right-circle"></div>
        </div>
    </div>
    <div id="progress-rate"
        title="浏览进度"
        style="color:#fff; font-size: 15px;text-align: center;padding-top: 8px;">
    </div>
</div>
<div id="changebg" class="sidebutton" style="position:fixed;bottom:70px;right:0px;cursor: pointer;">
    <a title="背景颜色"><img class="iconimg" src="/img/change.png"/></a>
</div>
<div id="totop" class="sidebutton" style="position:fixed;bottom:40px;right:0px;cursor: pointer;">
    <a title="返回顶部"><img class="iconimg" src="/img/scrollup.png"/></a>
</div>
<div id="todown" class="sidebutton" style="position:fixed;bottom:10px;right:0px;cursor: pointer;">
    <a title="到达底部"><img class="iconimg" src="/img/scrolldown.png"/></a>
</div>
<script src="/js/sidebutton.js"></script>
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/1koharu.model.json"},"display":{"position":"left","width":150,"height":300,"hOffset":50,"vOffset":-40},"mobile":{"show":false},"rect":"opacity:0.7","log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
<script>
  var hide = false;
  function myFunction(x) {
      x.classList.toggle("change");
      if(hide == false){
          $(".left-col").css('display', 'none');
          $(".mid-col").css("left", 6);
          $(".tools-col").css('display', 'none');
          $(".tools-col.hide").css('display', 'none');
          hide = true;
          $(".mymenucontainer").css('left', '0');
      }else{
          $(".left-col").css('display', '');
          $(".mid-col").css("left", 300);
          $(".tools-col").css('display', '');
          $(".tools-col.hide").css('display', '');
          hide = false;
          $(".mymenucontainer").css('left', '280px');
      }
  }
  if (localStorage.getItem('bright') === '1') {
    document.body.classList.add('bright');
  }
  // else if (new Date().getHours() >= 7 && new Date().getHours() < 22) {
  //   document.body.classList.add('bright');
  // }
  // else if (matchMedia('(prefers-color-scheme: light)').matches) {
  //   document.body.classList.add('bright');
  // }
</script>
</html>